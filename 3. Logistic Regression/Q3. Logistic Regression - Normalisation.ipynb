{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "For each version of data (z-normalization, log-transform and binarization) from the Data pre-processing section, fit a logistic regression model with $\\ l_2$ regularization. \n",
    "\n",
    "For each regularization parameter value λ = {1,2,··· ,9,10,15,20,··· ,95,100} (note the jump in interval from 10 to 15 and beyond), fit the logistic regression model on the training data and compute its error rate (i.e., percentage of emails classified wrongly) on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "The data is an email spam dataset, consisting of 4601 email messages with 57 features. Feature descriptions are found in this [link](https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.info.txt). We have divided the data into a training set (3605 emails) and test set (1536 emails) with accompanying labels (1=spam,0=not spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# A function to enable displaying the tables side by side\n",
    "def multi_table(table_list):\n",
    "    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n",
    "    '''\n",
    "    return HTML(\n",
    "        '<table><tr style=\"background-color:white;\">' + \n",
    "        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )\n",
    "\n",
    "# set seaborn style\n",
    "sns.set()\n",
    "\n",
    "# display 6 digit decimal float in Pandas DataFrame\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtrain. \n",
    "df_X = pd.read_csv('spamData_Xtrain.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytrain.\n",
    "df_y = pd.read_csv('spamData_ytrain.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtest. \n",
    "df_Xtest = pd.read_csv('spamData_Xtest.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytest.\n",
    "df_ytest = pd.read_csv('spamData_ytest.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N`: Number of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`D`: Number of training sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = df_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three preprocessing technique could be considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Z-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stdev(column):\n",
    "    avg = np.mean(column)\n",
    "    sd  = np.sum(np.square(column-avg))/(len(column)-1)\n",
    "    return np.sqrt(sd)\n",
    "\n",
    "def z_norm(column):\n",
    "    column = column - np.mean(column)\n",
    "    column = column/stdev(column)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Log-Transformation \n",
    "Transform each feature using $\\log(x_{i,j}+0.1)$ (assume natural log)\n",
    "\n",
    "The log transformation can be used to make highly skewed distributions less skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_X = np.log(df_X+0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Binarize(column):\n",
    "    \"\"\"For the input column, set values larger than the column mean to be 1, \n",
    "    rest set to be 0.\"\"\"\n",
    "    ones = column > column.mean()\n",
    "    zeros = column <= column.mean()\n",
    "    columnNew = pd.Series(np.zeros(len(column)))\n",
    "    columnNew[ones] = 1\n",
    "    return columnNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Preprocess the training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use z-normalization in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = df_X.apply(z_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest = df_Xtest.apply(z_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modify `df_X` and `df_w` for Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add bia term to X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias = pd.DataFrame(bias,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_X = pd.concat([df_bias,df_X],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the column name\n",
    "modified_column_name = np.arange(D+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_test = np.ones(len(df_Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias_test = pd.DataFrame(bias_test,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_Xtest = pd.concat([df_bias_test,df_Xtest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Initialize the modified weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and initialize the the weight vector to 0. \n",
    "\n",
    "\\# weight = # features + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = np.zeros([D+1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = pd.DataFrame(df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Put everything together\n",
    "Train the classifier, for each regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}\n",
    "\n",
    "Then, find the error rates (i.e., percentage of emails classified wrongly) for each $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  \"\"\"The sigmoid function\"\"\"\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def getErrorRate(prediction,y):\n",
    "    \"\"\"Calculate the percentage of emails classified wrongly\"\"\"\n",
    "    compare = prediction == y\n",
    "    errorRate = 1-compare.sum().values[0]/compare.shape[0]\n",
    "    return errorRate\n",
    "\n",
    "def findBestThreshold(pred,y):\n",
    "    \"\"\"Calculate error rate for threshold from 50 to 100,\n",
    "    find the threshold that produces the minimum error rate.\"\"\"\n",
    "    # create an array to store the error rate produced by each threshold.\n",
    "    store = np.zeros(50)\n",
    "    counter = 0\n",
    "    for i in np.arange(50,100):\n",
    "        ones = pred > (i/100)\n",
    "        pred_binary = pd.DataFrame(ones)\n",
    "        store[counter] = getErrorRate(pred_binary,y)\n",
    "        counter = counter +1\n",
    "    # find the index of the minimum error rate.     \n",
    "    resultIndex = np.argmin(store)\n",
    "    bestThreshold = np.arange(50,100)[resultIndex]\n",
    "    bestErrorRate = store[resultIndex]\n",
    "    return bestThreshold,bestErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I'$- `identity_modified`: set the first entry of the identity matrix $I$ to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_modified = np.ones(D+1)\n",
    "identity_modified[0] = 0 \n",
    "identity_modified = np.diag(identity_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = np.append(np.arange(1,10),np.arange(10,105,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`K` : number of regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_w_all`: a dataframe used to store all the weight vector from each regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w_all = pd.DataFrame(np.zeros((D+1,K)),columns=[params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_error_rate`: a dataframe used to store the error rate for each regularization parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_error_rate = pd.DataFrame(np.zeros((K,2)),index = params,columns=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For regulation parameter 1\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 10\n",
      "\n",
      "For regulation parameter 2\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 4\n",
      "\n",
      "For regulation parameter 3\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 4\n",
      "\n",
      "For regulation parameter 4\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 5\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 6\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 7\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 8\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 9\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 10\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 15\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 20\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 25\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 30\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 35\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 40\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 45\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 50\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 55\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 60\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 65\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 70\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 75\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 80\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 85\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 90\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 95\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 100\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "The weight vector obtained through the newton's method.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.39246</td>\n",
       "      <td>-0.12399</td>\n",
       "      <td>-0.23041</td>\n",
       "      <td>0.01188</td>\n",
       "      <td>0.78766</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>0.24769</td>\n",
       "      <td>1.30408</td>\n",
       "      <td>0.25954</td>\n",
       "      <td>0.12155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.71305</td>\n",
       "      <td>-0.25930</td>\n",
       "      <td>-0.04978</td>\n",
       "      <td>-0.26647</td>\n",
       "      <td>0.58761</td>\n",
       "      <td>1.05803</td>\n",
       "      <td>0.67853</td>\n",
       "      <td>-0.15353</td>\n",
       "      <td>0.79691</td>\n",
       "      <td>0.45227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.03374</td>\n",
       "      <td>-0.12045</td>\n",
       "      <td>-0.22012</td>\n",
       "      <td>0.01682</td>\n",
       "      <td>0.56557</td>\n",
       "      <td>0.44887</td>\n",
       "      <td>0.24124</td>\n",
       "      <td>1.26135</td>\n",
       "      <td>0.26410</td>\n",
       "      <td>0.12079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63207</td>\n",
       "      <td>-0.25554</td>\n",
       "      <td>-0.05059</td>\n",
       "      <td>-0.26630</td>\n",
       "      <td>0.59255</td>\n",
       "      <td>1.04218</td>\n",
       "      <td>0.57194</td>\n",
       "      <td>-0.11364</td>\n",
       "      <td>0.72060</td>\n",
       "      <td>0.42876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.82973</td>\n",
       "      <td>-0.11768</td>\n",
       "      <td>-0.21218</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.47880</td>\n",
       "      <td>0.44759</td>\n",
       "      <td>0.23754</td>\n",
       "      <td>1.22476</td>\n",
       "      <td>0.26740</td>\n",
       "      <td>0.12057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57581</td>\n",
       "      <td>-0.25204</td>\n",
       "      <td>-0.05090</td>\n",
       "      <td>-0.26012</td>\n",
       "      <td>0.59158</td>\n",
       "      <td>1.02491</td>\n",
       "      <td>0.50598</td>\n",
       "      <td>-0.08033</td>\n",
       "      <td>0.66172</td>\n",
       "      <td>0.41704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.68600</td>\n",
       "      <td>-0.11526</td>\n",
       "      <td>-0.20573</td>\n",
       "      <td>0.02366</td>\n",
       "      <td>0.42841</td>\n",
       "      <td>0.44569</td>\n",
       "      <td>0.23496</td>\n",
       "      <td>1.19319</td>\n",
       "      <td>0.27005</td>\n",
       "      <td>0.12065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.53393</td>\n",
       "      <td>-0.24854</td>\n",
       "      <td>-0.05106</td>\n",
       "      <td>-0.25340</td>\n",
       "      <td>0.58915</td>\n",
       "      <td>1.00792</td>\n",
       "      <td>0.46033</td>\n",
       "      <td>-0.05347</td>\n",
       "      <td>0.61577</td>\n",
       "      <td>0.40910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.57569</td>\n",
       "      <td>-0.11310</td>\n",
       "      <td>-0.20025</td>\n",
       "      <td>0.02628</td>\n",
       "      <td>0.39382</td>\n",
       "      <td>0.44340</td>\n",
       "      <td>0.23300</td>\n",
       "      <td>1.16540</td>\n",
       "      <td>0.27223</td>\n",
       "      <td>0.12090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50107</td>\n",
       "      <td>-0.24506</td>\n",
       "      <td>-0.05119</td>\n",
       "      <td>-0.24690</td>\n",
       "      <td>0.58643</td>\n",
       "      <td>0.99154</td>\n",
       "      <td>0.42641</td>\n",
       "      <td>-0.03189</td>\n",
       "      <td>0.57911</td>\n",
       "      <td>0.40289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.48680</td>\n",
       "      <td>-0.11112</td>\n",
       "      <td>-0.19548</td>\n",
       "      <td>0.02858</td>\n",
       "      <td>0.36788</td>\n",
       "      <td>0.44084</td>\n",
       "      <td>0.23142</td>\n",
       "      <td>1.14052</td>\n",
       "      <td>0.27404</td>\n",
       "      <td>0.12128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47429</td>\n",
       "      <td>-0.24167</td>\n",
       "      <td>-0.05130</td>\n",
       "      <td>-0.24081</td>\n",
       "      <td>0.58367</td>\n",
       "      <td>0.97585</td>\n",
       "      <td>0.39997</td>\n",
       "      <td>-0.01447</td>\n",
       "      <td>0.54915</td>\n",
       "      <td>0.39768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.41280</td>\n",
       "      <td>-0.10928</td>\n",
       "      <td>-0.19122</td>\n",
       "      <td>0.03061</td>\n",
       "      <td>0.34735</td>\n",
       "      <td>0.43809</td>\n",
       "      <td>0.23010</td>\n",
       "      <td>1.11798</td>\n",
       "      <td>0.27556</td>\n",
       "      <td>0.12174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45186</td>\n",
       "      <td>-0.23838</td>\n",
       "      <td>-0.05141</td>\n",
       "      <td>-0.23514</td>\n",
       "      <td>0.58090</td>\n",
       "      <td>0.96084</td>\n",
       "      <td>0.37862</td>\n",
       "      <td>-0.00033</td>\n",
       "      <td>0.52413</td>\n",
       "      <td>0.39315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.34976</td>\n",
       "      <td>-0.10755</td>\n",
       "      <td>-0.18736</td>\n",
       "      <td>0.03243</td>\n",
       "      <td>0.33049</td>\n",
       "      <td>0.43519</td>\n",
       "      <td>0.22897</td>\n",
       "      <td>1.09732</td>\n",
       "      <td>0.27683</td>\n",
       "      <td>0.12226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43267</td>\n",
       "      <td>-0.23522</td>\n",
       "      <td>-0.05153</td>\n",
       "      <td>-0.22989</td>\n",
       "      <td>0.57810</td>\n",
       "      <td>0.94648</td>\n",
       "      <td>0.36093</td>\n",
       "      <td>0.01125</td>\n",
       "      <td>0.50286</td>\n",
       "      <td>0.38912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.29513</td>\n",
       "      <td>-0.10592</td>\n",
       "      <td>-0.18382</td>\n",
       "      <td>0.03409</td>\n",
       "      <td>0.31630</td>\n",
       "      <td>0.43220</td>\n",
       "      <td>0.22799</td>\n",
       "      <td>1.07823</td>\n",
       "      <td>0.27789</td>\n",
       "      <td>0.12282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41598</td>\n",
       "      <td>-0.23220</td>\n",
       "      <td>-0.05165</td>\n",
       "      <td>-0.22501</td>\n",
       "      <td>0.57529</td>\n",
       "      <td>0.93273</td>\n",
       "      <td>0.34595</td>\n",
       "      <td>0.02082</td>\n",
       "      <td>0.48447</td>\n",
       "      <td>0.38548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.24724</td>\n",
       "      <td>-0.10437</td>\n",
       "      <td>-0.18055</td>\n",
       "      <td>0.03560</td>\n",
       "      <td>0.30412</td>\n",
       "      <td>0.42915</td>\n",
       "      <td>0.22713</td>\n",
       "      <td>1.06047</td>\n",
       "      <td>0.27877</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40126</td>\n",
       "      <td>-0.22930</td>\n",
       "      <td>-0.05178</td>\n",
       "      <td>-0.22045</td>\n",
       "      <td>0.57246</td>\n",
       "      <td>0.91957</td>\n",
       "      <td>0.33304</td>\n",
       "      <td>0.02880</td>\n",
       "      <td>0.46838</td>\n",
       "      <td>0.38214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.07633</td>\n",
       "      <td>-0.09778</td>\n",
       "      <td>-0.16696</td>\n",
       "      <td>0.04164</td>\n",
       "      <td>0.26168</td>\n",
       "      <td>0.41434</td>\n",
       "      <td>0.22383</td>\n",
       "      <td>0.98651</td>\n",
       "      <td>0.28113</td>\n",
       "      <td>0.12626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.34677</td>\n",
       "      <td>-0.21651</td>\n",
       "      <td>-0.05232</td>\n",
       "      <td>-0.20082</td>\n",
       "      <td>0.55893</td>\n",
       "      <td>0.86165</td>\n",
       "      <td>0.28746</td>\n",
       "      <td>0.05407</td>\n",
       "      <td>0.41003</td>\n",
       "      <td>0.36836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.97280</td>\n",
       "      <td>-0.09264</td>\n",
       "      <td>-0.15640</td>\n",
       "      <td>0.04614</td>\n",
       "      <td>0.23566</td>\n",
       "      <td>0.40139</td>\n",
       "      <td>0.22136</td>\n",
       "      <td>0.92954</td>\n",
       "      <td>0.28133</td>\n",
       "      <td>0.12863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.31041</td>\n",
       "      <td>-0.20591</td>\n",
       "      <td>-0.05265</td>\n",
       "      <td>-0.18471</td>\n",
       "      <td>0.54712</td>\n",
       "      <td>0.81447</td>\n",
       "      <td>0.25863</td>\n",
       "      <td>0.06688</td>\n",
       "      <td>0.37245</td>\n",
       "      <td>0.35731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.90341</td>\n",
       "      <td>-0.08837</td>\n",
       "      <td>-0.14777</td>\n",
       "      <td>0.04970</td>\n",
       "      <td>0.21751</td>\n",
       "      <td>0.39025</td>\n",
       "      <td>0.21929</td>\n",
       "      <td>0.88348</td>\n",
       "      <td>0.28041</td>\n",
       "      <td>0.13047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28368</td>\n",
       "      <td>-0.19692</td>\n",
       "      <td>-0.05284</td>\n",
       "      <td>-0.17135</td>\n",
       "      <td>0.53669</td>\n",
       "      <td>0.77514</td>\n",
       "      <td>0.23803</td>\n",
       "      <td>0.07410</td>\n",
       "      <td>0.34544</td>\n",
       "      <td>0.34792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.85339</td>\n",
       "      <td>-0.08465</td>\n",
       "      <td>-0.14052</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.20382</td>\n",
       "      <td>0.38056</td>\n",
       "      <td>0.21746</td>\n",
       "      <td>0.84497</td>\n",
       "      <td>0.27890</td>\n",
       "      <td>0.13190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26290</td>\n",
       "      <td>-0.18915</td>\n",
       "      <td>-0.05295</td>\n",
       "      <td>-0.16020</td>\n",
       "      <td>0.52721</td>\n",
       "      <td>0.74160</td>\n",
       "      <td>0.22223</td>\n",
       "      <td>0.07839</td>\n",
       "      <td>0.32470</td>\n",
       "      <td>0.33970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.81543</td>\n",
       "      <td>-0.08132</td>\n",
       "      <td>-0.13430</td>\n",
       "      <td>0.05509</td>\n",
       "      <td>0.19291</td>\n",
       "      <td>0.37203</td>\n",
       "      <td>0.21578</td>\n",
       "      <td>0.81200</td>\n",
       "      <td>0.27707</td>\n",
       "      <td>0.13299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24609</td>\n",
       "      <td>-0.18233</td>\n",
       "      <td>-0.05303</td>\n",
       "      <td>-0.15080</td>\n",
       "      <td>0.51843</td>\n",
       "      <td>0.71251</td>\n",
       "      <td>0.20953</td>\n",
       "      <td>0.08100</td>\n",
       "      <td>0.30804</td>\n",
       "      <td>0.33237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.78551</td>\n",
       "      <td>-0.07828</td>\n",
       "      <td>-0.12886</td>\n",
       "      <td>0.05719</td>\n",
       "      <td>0.18389</td>\n",
       "      <td>0.36444</td>\n",
       "      <td>0.21422</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.27507</td>\n",
       "      <td>0.13381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23214</td>\n",
       "      <td>-0.17627</td>\n",
       "      <td>-0.05308</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>0.51021</td>\n",
       "      <td>0.68691</td>\n",
       "      <td>0.19899</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.29422</td>\n",
       "      <td>0.32575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.76124</td>\n",
       "      <td>-0.07547</td>\n",
       "      <td>-0.12405</td>\n",
       "      <td>0.05901</td>\n",
       "      <td>0.17622</td>\n",
       "      <td>0.35760</td>\n",
       "      <td>0.21275</td>\n",
       "      <td>0.75780</td>\n",
       "      <td>0.27297</td>\n",
       "      <td>0.13443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.22030</td>\n",
       "      <td>-0.17083</td>\n",
       "      <td>-0.05311</td>\n",
       "      <td>-0.13585</td>\n",
       "      <td>0.50244</td>\n",
       "      <td>0.66412</td>\n",
       "      <td>0.19003</td>\n",
       "      <td>0.08349</td>\n",
       "      <td>0.28249</td>\n",
       "      <td>0.31968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.74111</td>\n",
       "      <td>-0.07284</td>\n",
       "      <td>-0.11976</td>\n",
       "      <td>0.06061</td>\n",
       "      <td>0.16957</td>\n",
       "      <td>0.35138</td>\n",
       "      <td>0.21134</td>\n",
       "      <td>0.73502</td>\n",
       "      <td>0.27082</td>\n",
       "      <td>0.13487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21009</td>\n",
       "      <td>-0.16590</td>\n",
       "      <td>-0.05312</td>\n",
       "      <td>-0.12981</td>\n",
       "      <td>0.49508</td>\n",
       "      <td>0.64364</td>\n",
       "      <td>0.18227</td>\n",
       "      <td>0.08396</td>\n",
       "      <td>0.27234</td>\n",
       "      <td>0.31409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.72411</td>\n",
       "      <td>-0.07038</td>\n",
       "      <td>-0.11588</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>0.16369</td>\n",
       "      <td>0.34569</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.71443</td>\n",
       "      <td>0.26867</td>\n",
       "      <td>0.13517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20116</td>\n",
       "      <td>-0.16140</td>\n",
       "      <td>-0.05313</td>\n",
       "      <td>-0.12450</td>\n",
       "      <td>0.48806</td>\n",
       "      <td>0.62508</td>\n",
       "      <td>0.17545</td>\n",
       "      <td>0.08413</td>\n",
       "      <td>0.26344</td>\n",
       "      <td>0.30889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.70953</td>\n",
       "      <td>-0.06805</td>\n",
       "      <td>-0.11235</td>\n",
       "      <td>0.06326</td>\n",
       "      <td>0.15844</td>\n",
       "      <td>0.34042</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.69569</td>\n",
       "      <td>0.26652</td>\n",
       "      <td>0.13537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19327</td>\n",
       "      <td>-0.15727</td>\n",
       "      <td>-0.05313</td>\n",
       "      <td>-0.11978</td>\n",
       "      <td>0.48137</td>\n",
       "      <td>0.60815</td>\n",
       "      <td>0.16938</td>\n",
       "      <td>0.08410</td>\n",
       "      <td>0.25554</td>\n",
       "      <td>0.30404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.69687</td>\n",
       "      <td>-0.06585</td>\n",
       "      <td>-0.10913</td>\n",
       "      <td>0.06438</td>\n",
       "      <td>0.15370</td>\n",
       "      <td>0.33553</td>\n",
       "      <td>0.20745</td>\n",
       "      <td>0.67849</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.13546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18623</td>\n",
       "      <td>-0.15345</td>\n",
       "      <td>-0.05311</td>\n",
       "      <td>-0.11556</td>\n",
       "      <td>0.47496</td>\n",
       "      <td>0.59262</td>\n",
       "      <td>0.16393</td>\n",
       "      <td>0.08391</td>\n",
       "      <td>0.24844</td>\n",
       "      <td>0.29948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.68576</td>\n",
       "      <td>-0.06376</td>\n",
       "      <td>-0.10616</td>\n",
       "      <td>0.06539</td>\n",
       "      <td>0.14937</td>\n",
       "      <td>0.33095</td>\n",
       "      <td>0.20623</td>\n",
       "      <td>0.66263</td>\n",
       "      <td>0.26230</td>\n",
       "      <td>0.13548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17990</td>\n",
       "      <td>-0.14991</td>\n",
       "      <td>-0.05310</td>\n",
       "      <td>-0.11176</td>\n",
       "      <td>0.46882</td>\n",
       "      <td>0.57828</td>\n",
       "      <td>0.15900</td>\n",
       "      <td>0.08363</td>\n",
       "      <td>0.24203</td>\n",
       "      <td>0.29518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.67592</td>\n",
       "      <td>-0.06176</td>\n",
       "      <td>-0.10342</td>\n",
       "      <td>0.06630</td>\n",
       "      <td>0.14539</td>\n",
       "      <td>0.32665</td>\n",
       "      <td>0.20504</td>\n",
       "      <td>0.64793</td>\n",
       "      <td>0.26024</td>\n",
       "      <td>0.13544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17417</td>\n",
       "      <td>-0.14660</td>\n",
       "      <td>-0.05307</td>\n",
       "      <td>-0.10831</td>\n",
       "      <td>0.46293</td>\n",
       "      <td>0.56500</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.08327</td>\n",
       "      <td>0.23619</td>\n",
       "      <td>0.29111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.66713</td>\n",
       "      <td>-0.05986</td>\n",
       "      <td>-0.10087</td>\n",
       "      <td>0.06713</td>\n",
       "      <td>0.14172</td>\n",
       "      <td>0.32260</td>\n",
       "      <td>0.20389</td>\n",
       "      <td>0.63424</td>\n",
       "      <td>0.25821</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16895</td>\n",
       "      <td>-0.14351</td>\n",
       "      <td>-0.05304</td>\n",
       "      <td>-0.10517</td>\n",
       "      <td>0.45727</td>\n",
       "      <td>0.55264</td>\n",
       "      <td>0.15038</td>\n",
       "      <td>0.08286</td>\n",
       "      <td>0.23083</td>\n",
       "      <td>0.28725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.65922</td>\n",
       "      <td>-0.05804</td>\n",
       "      <td>-0.09849</td>\n",
       "      <td>0.06788</td>\n",
       "      <td>0.13831</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.20276</td>\n",
       "      <td>0.62144</td>\n",
       "      <td>0.25622</td>\n",
       "      <td>0.13519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16416</td>\n",
       "      <td>-0.14060</td>\n",
       "      <td>-0.05300</td>\n",
       "      <td>-0.10230</td>\n",
       "      <td>0.45183</td>\n",
       "      <td>0.54109</td>\n",
       "      <td>0.14657</td>\n",
       "      <td>0.08241</td>\n",
       "      <td>0.22589</td>\n",
       "      <td>0.28357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.65205</td>\n",
       "      <td>-0.05629</td>\n",
       "      <td>-0.09626</td>\n",
       "      <td>0.06857</td>\n",
       "      <td>0.13512</td>\n",
       "      <td>0.31510</td>\n",
       "      <td>0.20166</td>\n",
       "      <td>0.60944</td>\n",
       "      <td>0.25426</td>\n",
       "      <td>0.13500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15975</td>\n",
       "      <td>-0.13786</td>\n",
       "      <td>-0.05295</td>\n",
       "      <td>-0.09965</td>\n",
       "      <td>0.44658</td>\n",
       "      <td>0.53027</td>\n",
       "      <td>0.14305</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.22132</td>\n",
       "      <td>0.28007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.64553</td>\n",
       "      <td>-0.05462</td>\n",
       "      <td>-0.09417</td>\n",
       "      <td>0.06920</td>\n",
       "      <td>0.13213</td>\n",
       "      <td>0.31161</td>\n",
       "      <td>0.20058</td>\n",
       "      <td>0.59815</td>\n",
       "      <td>0.25235</td>\n",
       "      <td>0.13478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15568</td>\n",
       "      <td>-0.13528</td>\n",
       "      <td>-0.05290</td>\n",
       "      <td>-0.09721</td>\n",
       "      <td>0.44153</td>\n",
       "      <td>0.52011</td>\n",
       "      <td>0.13978</td>\n",
       "      <td>0.08145</td>\n",
       "      <td>0.21707</td>\n",
       "      <td>0.27671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.63956</td>\n",
       "      <td>-0.05301</td>\n",
       "      <td>-0.09220</td>\n",
       "      <td>0.06978</td>\n",
       "      <td>0.12932</td>\n",
       "      <td>0.30828</td>\n",
       "      <td>0.19952</td>\n",
       "      <td>0.58749</td>\n",
       "      <td>0.25047</td>\n",
       "      <td>0.13453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15190</td>\n",
       "      <td>-0.13283</td>\n",
       "      <td>-0.05284</td>\n",
       "      <td>-0.09495</td>\n",
       "      <td>0.43665</td>\n",
       "      <td>0.51053</td>\n",
       "      <td>0.13672</td>\n",
       "      <td>0.08095</td>\n",
       "      <td>0.21309</td>\n",
       "      <td>0.27350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2       3       4       5       6       7   \\\n",
       "1   -2.39246 -0.12399 -0.23041 0.01188 0.78766 0.44959 0.24769 1.30408   \n",
       "2   -2.03374 -0.12045 -0.22012 0.01682 0.56557 0.44887 0.24124 1.26135   \n",
       "3   -1.82973 -0.11768 -0.21218 0.02058 0.47880 0.44759 0.23754 1.22476   \n",
       "4   -1.68600 -0.11526 -0.20573 0.02366 0.42841 0.44569 0.23496 1.19319   \n",
       "5   -1.57569 -0.11310 -0.20025 0.02628 0.39382 0.44340 0.23300 1.16540   \n",
       "6   -1.48680 -0.11112 -0.19548 0.02858 0.36788 0.44084 0.23142 1.14052   \n",
       "7   -1.41280 -0.10928 -0.19122 0.03061 0.34735 0.43809 0.23010 1.11798   \n",
       "8   -1.34976 -0.10755 -0.18736 0.03243 0.33049 0.43519 0.22897 1.09732   \n",
       "9   -1.29513 -0.10592 -0.18382 0.03409 0.31630 0.43220 0.22799 1.07823   \n",
       "10  -1.24724 -0.10437 -0.18055 0.03560 0.30412 0.42915 0.22713 1.06047   \n",
       "15  -1.07633 -0.09778 -0.16696 0.04164 0.26168 0.41434 0.22383 0.98651   \n",
       "20  -0.97280 -0.09264 -0.15640 0.04614 0.23566 0.40139 0.22136 0.92954   \n",
       "25  -0.90341 -0.08837 -0.14777 0.04970 0.21751 0.39025 0.21929 0.88348   \n",
       "30  -0.85339 -0.08465 -0.14052 0.05263 0.20382 0.38056 0.21746 0.84497   \n",
       "35  -0.81543 -0.08132 -0.13430 0.05509 0.19291 0.37203 0.21578 0.81200   \n",
       "40  -0.78551 -0.07828 -0.12886 0.05719 0.18389 0.36444 0.21422 0.78324   \n",
       "45  -0.76124 -0.07547 -0.12405 0.05901 0.17622 0.35760 0.21275 0.75780   \n",
       "50  -0.74111 -0.07284 -0.11976 0.06061 0.16957 0.35138 0.21134 0.73502   \n",
       "55  -0.72411 -0.07038 -0.11588 0.06201 0.16369 0.34569 0.21000 0.71443   \n",
       "60  -0.70953 -0.06805 -0.11235 0.06326 0.15844 0.34042 0.20870 0.69569   \n",
       "65  -0.69687 -0.06585 -0.10913 0.06438 0.15370 0.33553 0.20745 0.67849   \n",
       "70  -0.68576 -0.06376 -0.10616 0.06539 0.14937 0.33095 0.20623 0.66263   \n",
       "75  -0.67592 -0.06176 -0.10342 0.06630 0.14539 0.32665 0.20504 0.64793   \n",
       "80  -0.66713 -0.05986 -0.10087 0.06713 0.14172 0.32260 0.20389 0.63424   \n",
       "85  -0.65922 -0.05804 -0.09849 0.06788 0.13831 0.31875 0.20276 0.62144   \n",
       "90  -0.65205 -0.05629 -0.09626 0.06857 0.13512 0.31510 0.20166 0.60944   \n",
       "95  -0.64553 -0.05462 -0.09417 0.06920 0.13213 0.31161 0.20058 0.59815   \n",
       "100 -0.63956 -0.05301 -0.09220 0.06978 0.12932 0.30828 0.19952 0.58749   \n",
       "\n",
       "         8       9    ...         48       49       50       51      52  \\\n",
       "1   0.25954 0.12155   ...   -0.71305 -0.25930 -0.04978 -0.26647 0.58761   \n",
       "2   0.26410 0.12079   ...   -0.63207 -0.25554 -0.05059 -0.26630 0.59255   \n",
       "3   0.26740 0.12057   ...   -0.57581 -0.25204 -0.05090 -0.26012 0.59158   \n",
       "4   0.27005 0.12065   ...   -0.53393 -0.24854 -0.05106 -0.25340 0.58915   \n",
       "5   0.27223 0.12090   ...   -0.50107 -0.24506 -0.05119 -0.24690 0.58643   \n",
       "6   0.27404 0.12128   ...   -0.47429 -0.24167 -0.05130 -0.24081 0.58367   \n",
       "7   0.27556 0.12174   ...   -0.45186 -0.23838 -0.05141 -0.23514 0.58090   \n",
       "8   0.27683 0.12226   ...   -0.43267 -0.23522 -0.05153 -0.22989 0.57810   \n",
       "9   0.27789 0.12282   ...   -0.41598 -0.23220 -0.05165 -0.22501 0.57529   \n",
       "10  0.27877 0.12340   ...   -0.40126 -0.22930 -0.05178 -0.22045 0.57246   \n",
       "15  0.28113 0.12626   ...   -0.34677 -0.21651 -0.05232 -0.20082 0.55893   \n",
       "20  0.28133 0.12863   ...   -0.31041 -0.20591 -0.05265 -0.18471 0.54712   \n",
       "25  0.28041 0.13047   ...   -0.28368 -0.19692 -0.05284 -0.17135 0.53669   \n",
       "30  0.27890 0.13190   ...   -0.26290 -0.18915 -0.05295 -0.16020 0.52721   \n",
       "35  0.27707 0.13299   ...   -0.24609 -0.18233 -0.05303 -0.15080 0.51843   \n",
       "40  0.27507 0.13381   ...   -0.23214 -0.17627 -0.05308 -0.14277 0.51021   \n",
       "45  0.27297 0.13443   ...   -0.22030 -0.17083 -0.05311 -0.13585 0.50244   \n",
       "50  0.27082 0.13487   ...   -0.21009 -0.16590 -0.05312 -0.12981 0.49508   \n",
       "55  0.26867 0.13517   ...   -0.20116 -0.16140 -0.05313 -0.12450 0.48806   \n",
       "60  0.26652 0.13537   ...   -0.19327 -0.15727 -0.05313 -0.11978 0.48137   \n",
       "65  0.26440 0.13546   ...   -0.18623 -0.15345 -0.05311 -0.11556 0.47496   \n",
       "70  0.26230 0.13548   ...   -0.17990 -0.14991 -0.05310 -0.11176 0.46882   \n",
       "75  0.26024 0.13544   ...   -0.17417 -0.14660 -0.05307 -0.10831 0.46293   \n",
       "80  0.25821 0.13533   ...   -0.16895 -0.14351 -0.05304 -0.10517 0.45727   \n",
       "85  0.25622 0.13519   ...   -0.16416 -0.14060 -0.05300 -0.10230 0.45183   \n",
       "90  0.25426 0.13500   ...   -0.15975 -0.13786 -0.05295 -0.09965 0.44658   \n",
       "95  0.25235 0.13478   ...   -0.15568 -0.13528 -0.05290 -0.09721 0.44153   \n",
       "100 0.25047 0.13453   ...   -0.15190 -0.13283 -0.05284 -0.09495 0.43665   \n",
       "\n",
       "         53      54       55      56      57  \n",
       "1   1.05803 0.67853 -0.15353 0.79691 0.45227  \n",
       "2   1.04218 0.57194 -0.11364 0.72060 0.42876  \n",
       "3   1.02491 0.50598 -0.08033 0.66172 0.41704  \n",
       "4   1.00792 0.46033 -0.05347 0.61577 0.40910  \n",
       "5   0.99154 0.42641 -0.03189 0.57911 0.40289  \n",
       "6   0.97585 0.39997 -0.01447 0.54915 0.39768  \n",
       "7   0.96084 0.37862 -0.00033 0.52413 0.39315  \n",
       "8   0.94648 0.36093  0.01125 0.50286 0.38912  \n",
       "9   0.93273 0.34595  0.02082 0.48447 0.38548  \n",
       "10  0.91957 0.33304  0.02880 0.46838 0.38214  \n",
       "15  0.86165 0.28746  0.05407 0.41003 0.36836  \n",
       "20  0.81447 0.25863  0.06688 0.37245 0.35731  \n",
       "25  0.77514 0.23803  0.07410 0.34544 0.34792  \n",
       "30  0.74160 0.22223  0.07839 0.32470 0.33970  \n",
       "35  0.71251 0.20953  0.08100 0.30804 0.33237  \n",
       "40  0.68691 0.19899  0.08257 0.29422 0.32575  \n",
       "45  0.66412 0.19003  0.08349 0.28249 0.31968  \n",
       "50  0.64364 0.18227  0.08396 0.27234 0.31409  \n",
       "55  0.62508 0.17545  0.08413 0.26344 0.30889  \n",
       "60  0.60815 0.16938  0.08410 0.25554 0.30404  \n",
       "65  0.59262 0.16393  0.08391 0.24844 0.29948  \n",
       "70  0.57828 0.15900  0.08363 0.24203 0.29518  \n",
       "75  0.56500 0.15450  0.08327 0.23619 0.29111  \n",
       "80  0.55264 0.15038  0.08286 0.23083 0.28725  \n",
       "85  0.54109 0.14657  0.08241 0.22589 0.28357  \n",
       "90  0.53027 0.14305  0.08194 0.22132 0.28007  \n",
       "95  0.52011 0.13978  0.08145 0.21707 0.27671  \n",
       "100 0.51053 0.13672  0.08095 0.21309 0.27350  \n",
       "\n",
       "[28 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for L in params:\n",
    "    counter  = 0\n",
    "    for i in np.arange(500):\n",
    "        #_________________________________________________________#\n",
    "        ### 1. Calcualte mu \n",
    "        df_mu = df_X.dot(df_w)\n",
    "        df_mu = df_mu.apply(sigmoid)\n",
    "        \n",
    "        #_________________________________________________________#\n",
    "        ### 2. Calculate first derivative of NLL: g \n",
    "        df_w_modified = df_w.copy()\n",
    "        df_w_modified.iloc[0] = 0\n",
    "        df_g = df_X.transpose().dot(df_mu-df_y)+L*df_w_modified\n",
    "\n",
    "        #_________________________________________________________#\n",
    "        ### 3. Calculate second derivative of NLL: H     \n",
    "        df_S = df_mu*(1-df_mu)\n",
    "        df_S = np.diag(df_S.transpose().values.tolist()[0])\n",
    "        df_S = pd.DataFrame(df_S)\n",
    "\n",
    "        df_H = df_X.transpose().dot(df_S)\n",
    "        df_H = df_H.dot(df_X)\n",
    "        df_H = df_H + L*identity_modified\n",
    "        \n",
    "        #_________________________________________________________#  \n",
    "        ### 4. Update weight vector  \n",
    "        df_H_inverse = pd.DataFrame(np.linalg.pinv(df_H.values))\n",
    "        df_w_update = df_w - df_H_inverse.dot(df_g)\n",
    "        \n",
    "        #_________________________________________________________# \n",
    "        ### 5. Check whether the weight vector has already converged.       \n",
    "        if df_w_update.round(6).equals(df_w.round(6)):\n",
    "            # Store the converged weight vector.\n",
    "            df_w_all[L] = df_w[0]\n",
    "            \n",
    "            #_____________________________________________________# \n",
    "            ### 6.1. Calculate the error rate for training dataset. \n",
    "            df_pred = df_X.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_y)\n",
    "            df_error_rate.loc[L,'train'] = errorRate\n",
    "            \n",
    "            ### 6.2. Calculate the error rate for test dataset.\n",
    "            df_pred = df_Xtest.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_ytest)\n",
    "            df_error_rate.loc[L,'test'] = errorRate\n",
    "            break\n",
    "        else:\n",
    "            df_w = df_w_update\n",
    "            counter = counter + 1\n",
    "\n",
    "    if counter == 500:\n",
    "        print('Weight vector didnt converged')\n",
    "    else:\n",
    "        print('\\nFor regulation parameter',L)\n",
    "        print('Weight vector converged, training is over.')\n",
    "        print('Number of loop',counter)\n",
    "\n",
    "df_w_all = df_w_all.transpose()\n",
    "print(\"\\nThe weight vector obtained through the newton's method.\")\n",
    "display(df_w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The error rate when lambda = 1,10 and 100 is\n",
      "       train    test\n",
      "1   0.06362 0.07357\n",
      "10  0.06917 0.07943\n",
      "100 0.08320 0.09310\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe error rate when lambda = 1,10 and 100 is\\n',df_error_rate.loc[[1,10,100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the Graph: Error Rates versus $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.00000</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.07327</td>\n",
       "      <td>0.08361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00591</td>\n",
       "      <td>0.00589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.06362</td>\n",
       "      <td>0.07357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.06852</td>\n",
       "      <td>0.07861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.07194</td>\n",
       "      <td>0.08431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.07781</td>\n",
       "      <td>0.08870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.08320</td>\n",
       "      <td>0.09310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train     test\n",
       "count 28.00000 28.00000\n",
       "mean   0.07327  0.08361\n",
       "std    0.00591  0.00589\n",
       "min    0.06362  0.07357\n",
       "25%    0.06852  0.07861\n",
       "50%    0.07194  0.08431\n",
       "75%    0.07781  0.08870\n",
       "max    0.08320  0.09310"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error_rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the error rates to a csv file.\n",
    "df_error_rate.to_csv('Q3_ErrorRates_train_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169facf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the figure size\n",
    "fig=plt.figure(figsize=(9,6))\n",
    "\n",
    "# x axis: the regularization parameters lambda.\n",
    "x = df_error_rate.index.values\n",
    "# y axis: the error rates\n",
    "y1 = 100*df_error_rate.train.values\n",
    "y2 = 100*df_error_rate.test.values\n",
    "\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "\n",
    "plt.title('Error Rate for lambda = {1,2,...,9,10,15,20,...,95,100}',fontsize=15)\n",
    "plt.xlabel('lambda', fontsize=14)\n",
    "plt.ylabel('Error Rate %', fontsize=14)\n",
    "\n",
    "# legend\n",
    "plt.legend(('Training error', 'Test error'),fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
