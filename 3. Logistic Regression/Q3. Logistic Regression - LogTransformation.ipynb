{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "For each version of data (z-normalization, log-transform and binarization) from the Data pre-processing section, fit a logistic regression model with $\\ l_2$ regularization. \n",
    "\n",
    "For each regularization parameter value λ = {1,2,··· ,9,10,15,20,··· ,95,100} (note the jump in interval from 10 to 15 and beyond), fit the logistic regression model on the training data and compute its error rate (i.e., percentage of emails classified wrongly) on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "The data is an email spam dataset, consisting of 4601 email messages with 57 features. Feature descriptions are found in this [link](https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.info.txt). We have divided the data into a training set (3605 emails) and test set (1536 emails) with accompanying labels (1=spam,0=not spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# A function to enable displaying the tables side by side\n",
    "def multi_table(table_list):\n",
    "    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n",
    "    '''\n",
    "    return HTML(\n",
    "        '<table><tr style=\"background-color:white;\">' + \n",
    "        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )\n",
    "\n",
    "# set seaborn style\n",
    "sns.set()\n",
    "\n",
    "# display 6 digit decimal float in Pandas DataFrame\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtrain. \n",
    "df_X = pd.read_csv('spamData_Xtrain.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytrain.\n",
    "df_y = pd.read_csv('spamData_ytrain.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtest. \n",
    "df_Xtest = pd.read_csv('spamData_Xtest.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytest.\n",
    "df_ytest = pd.read_csv('spamData_ytest.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N`: Number of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`D`: Number of training sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = df_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three preprocessing technique could be considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Z-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stdev(column):\n",
    "    avg = np.mean(column)\n",
    "    sd  = np.sum(np.square(column-avg))/(len(column)-1)\n",
    "    return np.sqrt(sd)\n",
    "\n",
    "def z_norm(column):\n",
    "    column = column - np.mean(column)\n",
    "    column = column/stdev(column)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Log-Transformation \n",
    "Transform each feature using $\\log(x_{i,j}+0.1)$ (assume natural log)\n",
    "\n",
    "The log transformation can be used to make highly skewed distributions less skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_X = np.log(df_X+0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Binarize(column):\n",
    "    \"\"\"For the input column, set values larger than the column mean to be 1, \n",
    "    rest set to be 0.\"\"\"\n",
    "    ones = column > column.mean()\n",
    "    zeros = column <= column.mean()\n",
    "    columnNew = pd.Series(np.zeros(len(column)))\n",
    "    columnNew[ones] = 1\n",
    "    return columnNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Preprocess the training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use log-transformation in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = np.log(df_X+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest = np.log(df_Xtest+0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modify `df_X` and `df_w` for Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add bia term to X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias = pd.DataFrame(bias,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_X = pd.concat([df_bias,df_X],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the column name\n",
    "modified_column_name = np.arange(D+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_test = np.ones(len(df_Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias_test = pd.DataFrame(bias_test,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_Xtest = pd.concat([df_bias_test,df_Xtest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Initialize the modified weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and initialize the the weight vector to 0. \n",
    "\n",
    "\\# weight = # features + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = np.zeros([D+1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = pd.DataFrame(df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Put everything together\n",
    "Train the classifier, for each regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}\n",
    "\n",
    "Then, find the error rates (i.e., percentage of emails classified wrongly) for each $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  \"\"\"The sigmoid function\"\"\"\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def getErrorRate(prediction,y):\n",
    "    \"\"\"Calculate the percentage of emails classified wrongly\"\"\"\n",
    "    compare = prediction == y\n",
    "    errorRate = 1-compare.sum().values[0]/compare.shape[0]\n",
    "    return errorRate\n",
    "\n",
    "def findBestThreshold(pred,y):\n",
    "    \"\"\"Calculate error rate for threshold from 50 to 100,\n",
    "    find the threshold that produces the minimum error rate.\"\"\"\n",
    "    # create an array to store the error rate produced by each threshold.\n",
    "    store = np.zeros(50)\n",
    "    counter = 0\n",
    "    for i in np.arange(50,100):\n",
    "        ones = pred > (i/100)\n",
    "        pred_binary = pd.DataFrame(ones)\n",
    "        store[counter] = getErrorRate(pred_binary,y)\n",
    "        counter = counter +1\n",
    "    # find the index of the minimum error rate.     \n",
    "    resultIndex = np.argmin(store)\n",
    "    bestThreshold = np.arange(50,100)[resultIndex]\n",
    "    bestErrorRate = store[resultIndex]\n",
    "    return bestThreshold,bestErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I'$- `identity_modified`: set the first entry of the identity matrix $I$ to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_modified = np.ones(D+1)\n",
    "identity_modified[0] = 0 \n",
    "identity_modified = np.diag(identity_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = np.append(np.arange(1,10),np.arange(10,105,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`K` : number of regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_w_all`: a dataframe used to store all the weight vector from each regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w_all = pd.DataFrame(np.zeros((D+1,K)),columns=[params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_error_rate`: a dataframed used to store the error rate for each regularization parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_error_rate = pd.DataFrame(np.zeros((K,2)),index = params,columns=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For regulation parameter 1\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 10\n",
      "\n",
      "For regulation parameter 2\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 4\n",
      "\n",
      "For regulation parameter 3\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 4\n",
      "\n",
      "For regulation parameter 4\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 5\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 6\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 7\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 8\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 9\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 10\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 15\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 20\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 25\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 30\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 35\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 40\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 45\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 50\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 55\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 60\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 65\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 70\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 75\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 80\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 85\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 90\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 95\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 100\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "The weight vector obtained through the newton's method.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.56968</td>\n",
       "      <td>-0.25738</td>\n",
       "      <td>-0.06309</td>\n",
       "      <td>-0.35539</td>\n",
       "      <td>0.44916</td>\n",
       "      <td>0.55180</td>\n",
       "      <td>0.30675</td>\n",
       "      <td>1.21140</td>\n",
       "      <td>0.41779</td>\n",
       "      <td>0.04847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68468</td>\n",
       "      <td>-0.34903</td>\n",
       "      <td>-0.24680</td>\n",
       "      <td>-0.48373</td>\n",
       "      <td>0.88702</td>\n",
       "      <td>1.26540</td>\n",
       "      <td>-0.35077</td>\n",
       "      <td>0.73231</td>\n",
       "      <td>0.05370</td>\n",
       "      <td>0.54906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.00293</td>\n",
       "      <td>-0.24766</td>\n",
       "      <td>-0.06952</td>\n",
       "      <td>-0.33668</td>\n",
       "      <td>0.39008</td>\n",
       "      <td>0.53972</td>\n",
       "      <td>0.29505</td>\n",
       "      <td>1.16743</td>\n",
       "      <td>0.41157</td>\n",
       "      <td>0.05545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.61444</td>\n",
       "      <td>-0.32164</td>\n",
       "      <td>-0.22274</td>\n",
       "      <td>-0.41719</td>\n",
       "      <td>0.86924</td>\n",
       "      <td>1.20320</td>\n",
       "      <td>-0.29402</td>\n",
       "      <td>0.67015</td>\n",
       "      <td>0.08728</td>\n",
       "      <td>0.50688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.43932</td>\n",
       "      <td>-0.23916</td>\n",
       "      <td>-0.07228</td>\n",
       "      <td>-0.32157</td>\n",
       "      <td>0.35079</td>\n",
       "      <td>0.52934</td>\n",
       "      <td>0.28649</td>\n",
       "      <td>1.13069</td>\n",
       "      <td>0.40676</td>\n",
       "      <td>0.06055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.56234</td>\n",
       "      <td>-0.29976</td>\n",
       "      <td>-0.20585</td>\n",
       "      <td>-0.37357</td>\n",
       "      <td>0.85497</td>\n",
       "      <td>1.15513</td>\n",
       "      <td>-0.25391</td>\n",
       "      <td>0.62595</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.47665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.32590</td>\n",
       "      <td>-0.23160</td>\n",
       "      <td>-0.07361</td>\n",
       "      <td>-0.30863</td>\n",
       "      <td>0.32182</td>\n",
       "      <td>0.52011</td>\n",
       "      <td>0.27964</td>\n",
       "      <td>1.09898</td>\n",
       "      <td>0.40252</td>\n",
       "      <td>0.06449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52162</td>\n",
       "      <td>-0.28161</td>\n",
       "      <td>-0.19302</td>\n",
       "      <td>-0.34196</td>\n",
       "      <td>0.84271</td>\n",
       "      <td>1.11533</td>\n",
       "      <td>-0.22363</td>\n",
       "      <td>0.59207</td>\n",
       "      <td>0.12958</td>\n",
       "      <td>0.45315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-11.47066</td>\n",
       "      <td>-0.22481</td>\n",
       "      <td>-0.07419</td>\n",
       "      <td>-0.29724</td>\n",
       "      <td>0.29915</td>\n",
       "      <td>0.51176</td>\n",
       "      <td>0.27390</td>\n",
       "      <td>1.07107</td>\n",
       "      <td>0.39865</td>\n",
       "      <td>0.06762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48857</td>\n",
       "      <td>-0.26620</td>\n",
       "      <td>-0.18281</td>\n",
       "      <td>-0.31763</td>\n",
       "      <td>0.83181</td>\n",
       "      <td>1.08106</td>\n",
       "      <td>-0.19973</td>\n",
       "      <td>0.56483</td>\n",
       "      <td>0.14433</td>\n",
       "      <td>0.43401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-10.78264</td>\n",
       "      <td>-0.21864</td>\n",
       "      <td>-0.07432</td>\n",
       "      <td>-0.28703</td>\n",
       "      <td>0.28069</td>\n",
       "      <td>0.50412</td>\n",
       "      <td>0.26894</td>\n",
       "      <td>1.04614</td>\n",
       "      <td>0.39504</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.46100</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>-0.17445</td>\n",
       "      <td>-0.29811</td>\n",
       "      <td>0.82194</td>\n",
       "      <td>1.05083</td>\n",
       "      <td>-0.18026</td>\n",
       "      <td>0.54221</td>\n",
       "      <td>0.15650</td>\n",
       "      <td>0.41795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-10.21138</td>\n",
       "      <td>-0.21300</td>\n",
       "      <td>-0.07417</td>\n",
       "      <td>-0.27776</td>\n",
       "      <td>0.26524</td>\n",
       "      <td>0.49707</td>\n",
       "      <td>0.26455</td>\n",
       "      <td>1.02363</td>\n",
       "      <td>0.39165</td>\n",
       "      <td>0.07225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43752</td>\n",
       "      <td>-0.24125</td>\n",
       "      <td>-0.16744</td>\n",
       "      <td>-0.28197</td>\n",
       "      <td>0.81287</td>\n",
       "      <td>1.02373</td>\n",
       "      <td>-0.16402</td>\n",
       "      <td>0.52299</td>\n",
       "      <td>0.16676</td>\n",
       "      <td>0.40416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9.72597</td>\n",
       "      <td>-0.20781</td>\n",
       "      <td>-0.07381</td>\n",
       "      <td>-0.26927</td>\n",
       "      <td>0.25203</td>\n",
       "      <td>0.49052</td>\n",
       "      <td>0.26063</td>\n",
       "      <td>1.00312</td>\n",
       "      <td>0.38844</td>\n",
       "      <td>0.07397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.41717</td>\n",
       "      <td>-0.23095</td>\n",
       "      <td>-0.16147</td>\n",
       "      <td>-0.26832</td>\n",
       "      <td>0.80446</td>\n",
       "      <td>0.99913</td>\n",
       "      <td>-0.15021</td>\n",
       "      <td>0.50637</td>\n",
       "      <td>0.17554</td>\n",
       "      <td>0.39214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-9.30614</td>\n",
       "      <td>-0.20301</td>\n",
       "      <td>-0.07331</td>\n",
       "      <td>-0.26143</td>\n",
       "      <td>0.24055</td>\n",
       "      <td>0.48441</td>\n",
       "      <td>0.25706</td>\n",
       "      <td>0.98429</td>\n",
       "      <td>0.38538</td>\n",
       "      <td>0.07541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.39932</td>\n",
       "      <td>-0.22176</td>\n",
       "      <td>-0.15631</td>\n",
       "      <td>-0.25656</td>\n",
       "      <td>0.79660</td>\n",
       "      <td>0.97661</td>\n",
       "      <td>-0.13830</td>\n",
       "      <td>0.49179</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>0.38151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-8.93788</td>\n",
       "      <td>-0.19854</td>\n",
       "      <td>-0.07271</td>\n",
       "      <td>-0.25414</td>\n",
       "      <td>0.23045</td>\n",
       "      <td>0.47867</td>\n",
       "      <td>0.25379</td>\n",
       "      <td>0.96689</td>\n",
       "      <td>0.38245</td>\n",
       "      <td>0.07661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.38348</td>\n",
       "      <td>-0.21349</td>\n",
       "      <td>-0.15179</td>\n",
       "      <td>-0.24627</td>\n",
       "      <td>0.78922</td>\n",
       "      <td>0.95585</td>\n",
       "      <td>-0.12790</td>\n",
       "      <td>0.47885</td>\n",
       "      <td>0.18981</td>\n",
       "      <td>0.37202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-7.59419</td>\n",
       "      <td>-0.17996</td>\n",
       "      <td>-0.06885</td>\n",
       "      <td>-0.22395</td>\n",
       "      <td>0.19327</td>\n",
       "      <td>0.45429</td>\n",
       "      <td>0.24055</td>\n",
       "      <td>0.89571</td>\n",
       "      <td>0.36938</td>\n",
       "      <td>0.08023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32452</td>\n",
       "      <td>-0.18192</td>\n",
       "      <td>-0.13560</td>\n",
       "      <td>-0.20889</td>\n",
       "      <td>0.75758</td>\n",
       "      <td>0.87106</td>\n",
       "      <td>-0.09056</td>\n",
       "      <td>0.43059</td>\n",
       "      <td>0.21356</td>\n",
       "      <td>0.33613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-6.72050</td>\n",
       "      <td>-0.16565</td>\n",
       "      <td>-0.06453</td>\n",
       "      <td>-0.20076</td>\n",
       "      <td>0.16887</td>\n",
       "      <td>0.43494</td>\n",
       "      <td>0.23051</td>\n",
       "      <td>0.84199</td>\n",
       "      <td>0.35820</td>\n",
       "      <td>0.08153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28545</td>\n",
       "      <td>-0.16047</td>\n",
       "      <td>-0.12545</td>\n",
       "      <td>-0.18455</td>\n",
       "      <td>0.73201</td>\n",
       "      <td>0.80727</td>\n",
       "      <td>-0.06711</td>\n",
       "      <td>0.39835</td>\n",
       "      <td>0.22797</td>\n",
       "      <td>0.31186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-6.09245</td>\n",
       "      <td>-0.15405</td>\n",
       "      <td>-0.06025</td>\n",
       "      <td>-0.18206</td>\n",
       "      <td>0.15124</td>\n",
       "      <td>0.41891</td>\n",
       "      <td>0.22236</td>\n",
       "      <td>0.79905</td>\n",
       "      <td>0.34835</td>\n",
       "      <td>0.08169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25718</td>\n",
       "      <td>-0.14477</td>\n",
       "      <td>-0.11837</td>\n",
       "      <td>-0.16692</td>\n",
       "      <td>0.71042</td>\n",
       "      <td>0.75653</td>\n",
       "      <td>-0.05082</td>\n",
       "      <td>0.37473</td>\n",
       "      <td>0.23743</td>\n",
       "      <td>0.29408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-5.61257</td>\n",
       "      <td>-0.14433</td>\n",
       "      <td>-0.05618</td>\n",
       "      <td>-0.16647</td>\n",
       "      <td>0.13772</td>\n",
       "      <td>0.40524</td>\n",
       "      <td>0.21547</td>\n",
       "      <td>0.76342</td>\n",
       "      <td>0.33949</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23552</td>\n",
       "      <td>-0.13268</td>\n",
       "      <td>-0.11308</td>\n",
       "      <td>-0.15332</td>\n",
       "      <td>0.69167</td>\n",
       "      <td>0.71469</td>\n",
       "      <td>-0.03877</td>\n",
       "      <td>0.35635</td>\n",
       "      <td>0.24394</td>\n",
       "      <td>0.28036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-5.23041</td>\n",
       "      <td>-0.13598</td>\n",
       "      <td>-0.05237</td>\n",
       "      <td>-0.15319</td>\n",
       "      <td>0.12694</td>\n",
       "      <td>0.39335</td>\n",
       "      <td>0.20949</td>\n",
       "      <td>0.73307</td>\n",
       "      <td>0.33143</td>\n",
       "      <td>0.08045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21828</td>\n",
       "      <td>-0.12303</td>\n",
       "      <td>-0.10890</td>\n",
       "      <td>-0.14238</td>\n",
       "      <td>0.67506</td>\n",
       "      <td>0.67931</td>\n",
       "      <td>-0.02946</td>\n",
       "      <td>0.34146</td>\n",
       "      <td>0.24855</td>\n",
       "      <td>0.26939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-4.91682</td>\n",
       "      <td>-0.12868</td>\n",
       "      <td>-0.04882</td>\n",
       "      <td>-0.14167</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.38284</td>\n",
       "      <td>0.20420</td>\n",
       "      <td>0.70670</td>\n",
       "      <td>0.32402</td>\n",
       "      <td>0.07949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20415</td>\n",
       "      <td>-0.11512</td>\n",
       "      <td>-0.10548</td>\n",
       "      <td>-0.13331</td>\n",
       "      <td>0.66014</td>\n",
       "      <td>0.64882</td>\n",
       "      <td>-0.02205</td>\n",
       "      <td>0.32902</td>\n",
       "      <td>0.25187</td>\n",
       "      <td>0.26039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-4.65355</td>\n",
       "      <td>-0.12222</td>\n",
       "      <td>-0.04553</td>\n",
       "      <td>-0.13154</td>\n",
       "      <td>0.11067</td>\n",
       "      <td>0.37343</td>\n",
       "      <td>0.19946</td>\n",
       "      <td>0.68344</td>\n",
       "      <td>0.31716</td>\n",
       "      <td>0.07845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19231</td>\n",
       "      <td>-0.10848</td>\n",
       "      <td>-0.10258</td>\n",
       "      <td>-0.12563</td>\n",
       "      <td>0.64657</td>\n",
       "      <td>0.62214</td>\n",
       "      <td>-0.01600</td>\n",
       "      <td>0.31839</td>\n",
       "      <td>0.25428</td>\n",
       "      <td>0.25284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-4.42852</td>\n",
       "      <td>-0.11642</td>\n",
       "      <td>-0.04247</td>\n",
       "      <td>-0.12254</td>\n",
       "      <td>0.10433</td>\n",
       "      <td>0.36493</td>\n",
       "      <td>0.19516</td>\n",
       "      <td>0.66266</td>\n",
       "      <td>0.31077</td>\n",
       "      <td>0.07736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18220</td>\n",
       "      <td>-0.10282</td>\n",
       "      <td>-0.10007</td>\n",
       "      <td>-0.11901</td>\n",
       "      <td>0.63414</td>\n",
       "      <td>0.59852</td>\n",
       "      <td>-0.01096</td>\n",
       "      <td>0.30914</td>\n",
       "      <td>0.25604</td>\n",
       "      <td>0.24641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-4.23335</td>\n",
       "      <td>-0.11118</td>\n",
       "      <td>-0.03962</td>\n",
       "      <td>-0.11446</td>\n",
       "      <td>0.09884</td>\n",
       "      <td>0.35719</td>\n",
       "      <td>0.19122</td>\n",
       "      <td>0.64391</td>\n",
       "      <td>0.30480</td>\n",
       "      <td>0.07628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17345</td>\n",
       "      <td>-0.09793</td>\n",
       "      <td>-0.09786</td>\n",
       "      <td>-0.11323</td>\n",
       "      <td>0.62265</td>\n",
       "      <td>0.57739</td>\n",
       "      <td>-0.00672</td>\n",
       "      <td>0.30098</td>\n",
       "      <td>0.25730</td>\n",
       "      <td>0.24085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-4.06204</td>\n",
       "      <td>-0.10641</td>\n",
       "      <td>-0.03696</td>\n",
       "      <td>-0.10716</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.35008</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.62686</td>\n",
       "      <td>0.29918</td>\n",
       "      <td>0.07521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16578</td>\n",
       "      <td>-0.09364</td>\n",
       "      <td>-0.09587</td>\n",
       "      <td>-0.10813</td>\n",
       "      <td>0.61197</td>\n",
       "      <td>0.55834</td>\n",
       "      <td>-0.00308</td>\n",
       "      <td>0.29369</td>\n",
       "      <td>0.25818</td>\n",
       "      <td>0.23599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-3.91015</td>\n",
       "      <td>-0.10203</td>\n",
       "      <td>-0.03449</td>\n",
       "      <td>-0.10052</td>\n",
       "      <td>0.08977</td>\n",
       "      <td>0.34352</td>\n",
       "      <td>0.18424</td>\n",
       "      <td>0.61124</td>\n",
       "      <td>0.29389</td>\n",
       "      <td>0.07417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15899</td>\n",
       "      <td>-0.08986</td>\n",
       "      <td>-0.09406</td>\n",
       "      <td>-0.10357</td>\n",
       "      <td>0.60199</td>\n",
       "      <td>0.54104</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.28711</td>\n",
       "      <td>0.25877</td>\n",
       "      <td>0.23170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-3.77429</td>\n",
       "      <td>-0.09800</td>\n",
       "      <td>-0.03217</td>\n",
       "      <td>-0.09445</td>\n",
       "      <td>0.08597</td>\n",
       "      <td>0.33744</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.59685</td>\n",
       "      <td>0.28888</td>\n",
       "      <td>0.07316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15293</td>\n",
       "      <td>-0.08648</td>\n",
       "      <td>-0.09241</td>\n",
       "      <td>-0.09948</td>\n",
       "      <td>0.59263</td>\n",
       "      <td>0.52523</td>\n",
       "      <td>0.00279</td>\n",
       "      <td>0.28112</td>\n",
       "      <td>0.25914</td>\n",
       "      <td>0.22788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-3.65189</td>\n",
       "      <td>-0.09426</td>\n",
       "      <td>-0.03000</td>\n",
       "      <td>-0.08886</td>\n",
       "      <td>0.08256</td>\n",
       "      <td>0.33177</td>\n",
       "      <td>0.17817</td>\n",
       "      <td>0.58352</td>\n",
       "      <td>0.28413</td>\n",
       "      <td>0.07219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14747</td>\n",
       "      <td>-0.08344</td>\n",
       "      <td>-0.09087</td>\n",
       "      <td>-0.09578</td>\n",
       "      <td>0.58381</td>\n",
       "      <td>0.51070</td>\n",
       "      <td>0.00519</td>\n",
       "      <td>0.27564</td>\n",
       "      <td>0.25932</td>\n",
       "      <td>0.22445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-3.54087</td>\n",
       "      <td>-0.09078</td>\n",
       "      <td>-0.02796</td>\n",
       "      <td>-0.08369</td>\n",
       "      <td>0.07947</td>\n",
       "      <td>0.32646</td>\n",
       "      <td>0.17542</td>\n",
       "      <td>0.57111</td>\n",
       "      <td>0.27961</td>\n",
       "      <td>0.07125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14253</td>\n",
       "      <td>-0.08069</td>\n",
       "      <td>-0.08945</td>\n",
       "      <td>-0.09241</td>\n",
       "      <td>0.57547</td>\n",
       "      <td>0.49728</td>\n",
       "      <td>0.00731</td>\n",
       "      <td>0.27058</td>\n",
       "      <td>0.25935</td>\n",
       "      <td>0.22135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-3.43960</td>\n",
       "      <td>-0.08754</td>\n",
       "      <td>-0.02604</td>\n",
       "      <td>-0.07890</td>\n",
       "      <td>0.07666</td>\n",
       "      <td>0.32148</td>\n",
       "      <td>0.17283</td>\n",
       "      <td>0.55951</td>\n",
       "      <td>0.27531</td>\n",
       "      <td>0.07036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13802</td>\n",
       "      <td>-0.07819</td>\n",
       "      <td>-0.08811</td>\n",
       "      <td>-0.08932</td>\n",
       "      <td>0.56756</td>\n",
       "      <td>0.48485</td>\n",
       "      <td>0.00919</td>\n",
       "      <td>0.26590</td>\n",
       "      <td>0.25927</td>\n",
       "      <td>0.21854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-3.34676</td>\n",
       "      <td>-0.08450</td>\n",
       "      <td>-0.02424</td>\n",
       "      <td>-0.07445</td>\n",
       "      <td>0.07409</td>\n",
       "      <td>0.31678</td>\n",
       "      <td>0.17037</td>\n",
       "      <td>0.54864</td>\n",
       "      <td>0.27121</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13389</td>\n",
       "      <td>-0.07590</td>\n",
       "      <td>-0.08685</td>\n",
       "      <td>-0.08649</td>\n",
       "      <td>0.56005</td>\n",
       "      <td>0.47327</td>\n",
       "      <td>0.01088</td>\n",
       "      <td>0.26153</td>\n",
       "      <td>0.25908</td>\n",
       "      <td>0.21597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-3.26126</td>\n",
       "      <td>-0.08164</td>\n",
       "      <td>-0.02253</td>\n",
       "      <td>-0.07028</td>\n",
       "      <td>0.07173</td>\n",
       "      <td>0.31235</td>\n",
       "      <td>0.16805</td>\n",
       "      <td>0.53841</td>\n",
       "      <td>0.26728</td>\n",
       "      <td>0.06868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13009</td>\n",
       "      <td>-0.07379</td>\n",
       "      <td>-0.08566</td>\n",
       "      <td>-0.08387</td>\n",
       "      <td>0.55288</td>\n",
       "      <td>0.46247</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.25745</td>\n",
       "      <td>0.25882</td>\n",
       "      <td>0.21360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-3.18219</td>\n",
       "      <td>-0.07895</td>\n",
       "      <td>-0.02092</td>\n",
       "      <td>-0.06639</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.30815</td>\n",
       "      <td>0.16584</td>\n",
       "      <td>0.52877</td>\n",
       "      <td>0.26352</td>\n",
       "      <td>0.06790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12657</td>\n",
       "      <td>-0.07185</td>\n",
       "      <td>-0.08452</td>\n",
       "      <td>-0.08144</td>\n",
       "      <td>0.54604</td>\n",
       "      <td>0.45234</td>\n",
       "      <td>0.01376</td>\n",
       "      <td>0.25362</td>\n",
       "      <td>0.25850</td>\n",
       "      <td>0.21143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3       4       5       6       7   \\\n",
       "1   -17.56968 -0.25738 -0.06309 -0.35539 0.44916 0.55180 0.30675 1.21140   \n",
       "2   -15.00293 -0.24766 -0.06952 -0.33668 0.39008 0.53972 0.29505 1.16743   \n",
       "3   -13.43932 -0.23916 -0.07228 -0.32157 0.35079 0.52934 0.28649 1.13069   \n",
       "4   -12.32590 -0.23160 -0.07361 -0.30863 0.32182 0.52011 0.27964 1.09898   \n",
       "5   -11.47066 -0.22481 -0.07419 -0.29724 0.29915 0.51176 0.27390 1.07107   \n",
       "6   -10.78264 -0.21864 -0.07432 -0.28703 0.28069 0.50412 0.26894 1.04614   \n",
       "7   -10.21138 -0.21300 -0.07417 -0.27776 0.26524 0.49707 0.26455 1.02363   \n",
       "8    -9.72597 -0.20781 -0.07381 -0.26927 0.25203 0.49052 0.26063 1.00312   \n",
       "9    -9.30614 -0.20301 -0.07331 -0.26143 0.24055 0.48441 0.25706 0.98429   \n",
       "10   -8.93788 -0.19854 -0.07271 -0.25414 0.23045 0.47867 0.25379 0.96689   \n",
       "15   -7.59419 -0.17996 -0.06885 -0.22395 0.19327 0.45429 0.24055 0.89571   \n",
       "20   -6.72050 -0.16565 -0.06453 -0.20076 0.16887 0.43494 0.23051 0.84199   \n",
       "25   -6.09245 -0.15405 -0.06025 -0.18206 0.15124 0.41891 0.22236 0.79905   \n",
       "30   -5.61257 -0.14433 -0.05618 -0.16647 0.13772 0.40524 0.21547 0.76342   \n",
       "35   -5.23041 -0.13598 -0.05237 -0.15319 0.12694 0.39335 0.20949 0.73307   \n",
       "40   -4.91682 -0.12868 -0.04882 -0.14167 0.11810 0.38284 0.20420 0.70670   \n",
       "45   -4.65355 -0.12222 -0.04553 -0.13154 0.11067 0.37343 0.19946 0.68344   \n",
       "50   -4.42852 -0.11642 -0.04247 -0.12254 0.10433 0.36493 0.19516 0.66266   \n",
       "55   -4.23335 -0.11118 -0.03962 -0.11446 0.09884 0.35719 0.19122 0.64391   \n",
       "60   -4.06204 -0.10641 -0.03696 -0.10716 0.09403 0.35008 0.18760 0.62686   \n",
       "65   -3.91015 -0.10203 -0.03449 -0.10052 0.08977 0.34352 0.18424 0.61124   \n",
       "70   -3.77429 -0.09800 -0.03217 -0.09445 0.08597 0.33744 0.18110 0.59685   \n",
       "75   -3.65189 -0.09426 -0.03000 -0.08886 0.08256 0.33177 0.17817 0.58352   \n",
       "80   -3.54087 -0.09078 -0.02796 -0.08369 0.07947 0.32646 0.17542 0.57111   \n",
       "85   -3.43960 -0.08754 -0.02604 -0.07890 0.07666 0.32148 0.17283 0.55951   \n",
       "90   -3.34676 -0.08450 -0.02424 -0.07445 0.07409 0.31678 0.17037 0.54864   \n",
       "95   -3.26126 -0.08164 -0.02253 -0.07028 0.07173 0.31235 0.16805 0.53841   \n",
       "100  -3.18219 -0.07895 -0.02092 -0.06639 0.06955 0.30815 0.16584 0.52877   \n",
       "\n",
       "         8       9    ...         48       49       50       51      52  \\\n",
       "1   0.41779 0.04847   ...   -0.68468 -0.34903 -0.24680 -0.48373 0.88702   \n",
       "2   0.41157 0.05545   ...   -0.61444 -0.32164 -0.22274 -0.41719 0.86924   \n",
       "3   0.40676 0.06055   ...   -0.56234 -0.29976 -0.20585 -0.37357 0.85497   \n",
       "4   0.40252 0.06449   ...   -0.52162 -0.28161 -0.19302 -0.34196 0.84271   \n",
       "5   0.39865 0.06762   ...   -0.48857 -0.26620 -0.18281 -0.31763 0.83181   \n",
       "6   0.39504 0.07016   ...   -0.46100 -0.25289 -0.17445 -0.29811 0.82194   \n",
       "7   0.39165 0.07225   ...   -0.43752 -0.24125 -0.16744 -0.28197 0.81287   \n",
       "8   0.38844 0.07397   ...   -0.41717 -0.23095 -0.16147 -0.26832 0.80446   \n",
       "9   0.38538 0.07541   ...   -0.39932 -0.22176 -0.15631 -0.25656 0.79660   \n",
       "10  0.38245 0.07661   ...   -0.38348 -0.21349 -0.15179 -0.24627 0.78922   \n",
       "15  0.36938 0.08023   ...   -0.32452 -0.18192 -0.13560 -0.20889 0.75758   \n",
       "20  0.35820 0.08153   ...   -0.28545 -0.16047 -0.12545 -0.18455 0.73201   \n",
       "25  0.34835 0.08169   ...   -0.25718 -0.14477 -0.11837 -0.16692 0.71042   \n",
       "30  0.33949 0.08123   ...   -0.23552 -0.13268 -0.11308 -0.15332 0.69167   \n",
       "35  0.33143 0.08045   ...   -0.21828 -0.12303 -0.10890 -0.14238 0.67506   \n",
       "40  0.32402 0.07949   ...   -0.20415 -0.11512 -0.10548 -0.13331 0.66014   \n",
       "45  0.31716 0.07845   ...   -0.19231 -0.10848 -0.10258 -0.12563 0.64657   \n",
       "50  0.31077 0.07736   ...   -0.18220 -0.10282 -0.10007 -0.11901 0.63414   \n",
       "55  0.30480 0.07628   ...   -0.17345 -0.09793 -0.09786 -0.11323 0.62265   \n",
       "60  0.29918 0.07521   ...   -0.16578 -0.09364 -0.09587 -0.10813 0.61197   \n",
       "65  0.29389 0.07417   ...   -0.15899 -0.08986 -0.09406 -0.10357 0.60199   \n",
       "70  0.28888 0.07316   ...   -0.15293 -0.08648 -0.09241 -0.09948 0.59263   \n",
       "75  0.28413 0.07219   ...   -0.14747 -0.08344 -0.09087 -0.09578 0.58381   \n",
       "80  0.27961 0.07125   ...   -0.14253 -0.08069 -0.08945 -0.09241 0.57547   \n",
       "85  0.27531 0.07036   ...   -0.13802 -0.07819 -0.08811 -0.08932 0.56756   \n",
       "90  0.27121 0.06950   ...   -0.13389 -0.07590 -0.08685 -0.08649 0.56005   \n",
       "95  0.26728 0.06868   ...   -0.13009 -0.07379 -0.08566 -0.08387 0.55288   \n",
       "100 0.26352 0.06790   ...   -0.12657 -0.07185 -0.08452 -0.08144 0.54604   \n",
       "\n",
       "         53       54      55      56      57  \n",
       "1   1.26540 -0.35077 0.73231 0.05370 0.54906  \n",
       "2   1.20320 -0.29402 0.67015 0.08728 0.50688  \n",
       "3   1.15513 -0.25391 0.62595 0.11120 0.47665  \n",
       "4   1.11533 -0.22363 0.59207 0.12958 0.45315  \n",
       "5   1.08106 -0.19973 0.56483 0.14433 0.43401  \n",
       "6   1.05083 -0.18026 0.54221 0.15650 0.41795  \n",
       "7   1.02373 -0.16402 0.52299 0.16676 0.40416  \n",
       "8   0.99913 -0.15021 0.50637 0.17554 0.39214  \n",
       "9   0.97661 -0.13830 0.49179 0.18315 0.38151  \n",
       "10  0.95585 -0.12790 0.47885 0.18981 0.37202  \n",
       "15  0.87106 -0.09056 0.43059 0.21356 0.33613  \n",
       "20  0.80727 -0.06711 0.39835 0.22797 0.31186  \n",
       "25  0.75653 -0.05082 0.37473 0.23743 0.29408  \n",
       "30  0.71469 -0.03877 0.35635 0.24394 0.28036  \n",
       "35  0.67931 -0.02946 0.34146 0.24855 0.26939  \n",
       "40  0.64882 -0.02205 0.32902 0.25187 0.26039  \n",
       "45  0.62214 -0.01600 0.31839 0.25428 0.25284  \n",
       "50  0.59852 -0.01096 0.30914 0.25604 0.24641  \n",
       "55  0.57739 -0.00672 0.30098 0.25730 0.24085  \n",
       "60  0.55834 -0.00308 0.29369 0.25818 0.23599  \n",
       "65  0.54104  0.00005 0.28711 0.25877 0.23170  \n",
       "70  0.52523  0.00279 0.28112 0.25914 0.22788  \n",
       "75  0.51070  0.00519 0.27564 0.25932 0.22445  \n",
       "80  0.49728  0.00731 0.27058 0.25935 0.22135  \n",
       "85  0.48485  0.00919 0.26590 0.25927 0.21854  \n",
       "90  0.47327  0.01088 0.26153 0.25908 0.21597  \n",
       "95  0.46247  0.01239 0.25745 0.25882 0.21360  \n",
       "100 0.45234  0.01376 0.25362 0.25850 0.21143  \n",
       "\n",
       "[28 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for L in params:\n",
    "    counter  = 0\n",
    "    for i in np.arange(500):\n",
    "        #_________________________________________________________#\n",
    "        ### 1. Calcualte mu \n",
    "        df_mu = df_X.dot(df_w)\n",
    "        df_mu = df_mu.apply(sigmoid)\n",
    "        \n",
    "        #_________________________________________________________#\n",
    "        ### 2. Calculate first derivative of NLL: g \n",
    "        df_w_modified = df_w.copy()\n",
    "        df_w_modified.iloc[0] = 0\n",
    "        df_g = df_X.transpose().dot(df_mu-df_y)+L*df_w_modified\n",
    "\n",
    "        #_________________________________________________________#\n",
    "        ### 3. Calculate second derivative of NLL: H     \n",
    "        df_S = df_mu*(1-df_mu)\n",
    "        df_S = np.diag(df_S.transpose().values.tolist()[0])\n",
    "        df_S = pd.DataFrame(df_S)\n",
    "\n",
    "        df_H = df_X.transpose().dot(df_S)\n",
    "        df_H = df_H.dot(df_X)\n",
    "        df_H = df_H + L*identity_modified\n",
    "        \n",
    "        #_________________________________________________________#  \n",
    "        ### 4. Update weight vector  \n",
    "        df_H_inverse = pd.DataFrame(np.linalg.pinv(df_H.values))\n",
    "        df_w_update = df_w - df_H_inverse.dot(df_g)\n",
    "        \n",
    "        #_________________________________________________________# \n",
    "        ### 5. Check whether the weight vector has already converged.       \n",
    "        if df_w_update.round(6).equals(df_w.round(6)):\n",
    "            # Store the converged weight vector.\n",
    "            df_w_all[L] = df_w[0]\n",
    "            \n",
    "            #_____________________________________________________# \n",
    "            ### 6.1. Calculate the error rate for training dataset. \n",
    "            df_pred = df_X.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_y)\n",
    "            df_error_rate.loc[L,'train'] = errorRate\n",
    "            \n",
    "            ### 6.2. Calculate the error rate for test dataset.\n",
    "            df_pred = df_Xtest.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_ytest)\n",
    "            df_error_rate.loc[L,'test'] = errorRate\n",
    "            break\n",
    "        else:\n",
    "            df_w = df_w_update\n",
    "            counter = counter + 1\n",
    "\n",
    "    if counter == 500:\n",
    "        print('Weight vector didnt converged')\n",
    "    else:\n",
    "        print('\\nFor regulation parameter',L)\n",
    "        print('Weight vector converged, training is over.')\n",
    "        print('Number of loop',counter)\n",
    "\n",
    "df_w_all = df_w_all.transpose()\n",
    "print(\"\\nThe weight vector obtained through the newton's method.\")\n",
    "display(df_w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The error rate when lambda = 1,10 and 100 is\n",
      "       train    test\n",
      "1   0.04763 0.05924\n",
      "10  0.05024 0.06055\n",
      "100 0.05938 0.06641\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe error rate when lambda = 1,10 and 100 is\\n',df_error_rate.loc[[1,10,100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the Graph: Error Rates versus $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.00000</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.05299</td>\n",
       "      <td>0.06259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.00246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.04763</td>\n",
       "      <td>0.05859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.04951</td>\n",
       "      <td>0.06055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.05253</td>\n",
       "      <td>0.06185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.05620</td>\n",
       "      <td>0.06510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.05938</td>\n",
       "      <td>0.06641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train     test\n",
       "count 28.00000 28.00000\n",
       "mean   0.05299  0.06259\n",
       "std    0.00372  0.00246\n",
       "min    0.04763  0.05859\n",
       "25%    0.04951  0.06055\n",
       "50%    0.05253  0.06185\n",
       "75%    0.05620  0.06510\n",
       "max    0.05938  0.06641"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error_rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the error rates to a csv file.\n",
    "df_error_rate.to_csv('Q3_ErrorRates_Log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGHCAYAAABBFAMBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14b224a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the figure size\n",
    "fig=plt.figure(figsize=(9,6))\n",
    "\n",
    "# x axis: the regularization parameters lambda.\n",
    "x = df_error_rate.index.values\n",
    "# y axis: the error rates\n",
    "y1 = 100*df_error_rate.train.values\n",
    "y2 = 100*df_error_rate.test.values\n",
    "\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "\n",
    "plt.title('Error Rate for lambda = {1,2,...,9,10,15,20,...,95,100}',fontsize=15)\n",
    "plt.xlabel('lambda', fontsize=14)\n",
    "plt.ylabel('Error Rate %', fontsize=14)\n",
    "\n",
    "# legend\n",
    "plt.legend(('Training error', 'Test error'),fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
