{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "For each version of data (z-normalization, log-transform and binarization) from the Data Preprocessing section, fit a logistic regression model with $\\ l_2$ regularization. \n",
    "\n",
    "For each regularization parameter value λ = {1,2,··· ,9,10,15,20,··· ,95,100} (note the jump in interval from 10 to 15 and beyond), fit the logistic regression model on the training data and compute its error rate (i.e., percentage of emails classified wrongly) on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "The data is an email spam dataset, consisting of 4601 email messages with 57 features. Feature descriptions are found in this [link](https://web.stanford.edu/~hastie/ElemStatLearn/datasets/spam.info.txt). We have divided the data into a training set (3605 emails) and test set (1536 emails) with accompanying labels (1=spam,0=not spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# A function to enable displaying the tables side by side\n",
    "def multi_table(table_list):\n",
    "    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n",
    "    '''\n",
    "    return HTML(\n",
    "        '<table><tr style=\"background-color:white;\">' + \n",
    "        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n",
    "        '</tr></table>'\n",
    "    )\n",
    "\n",
    "# set seaborn style\n",
    "sns.set()\n",
    "\n",
    "# display 6 digit decimal float in Pandas DataFrame\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtrain. \n",
    "df_X = pd.read_csv('spamData_Xtrain.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytrain.\n",
    "df_y = pd.read_csv('spamData_ytrain.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame from csv file for Xtest. \n",
    "df_Xtest = pd.read_csv('spamData_Xtest.csv',header=None)\n",
    "# Creating a DataFrame from csv file for ytest.\n",
    "df_ytest = pd.read_csv('spamData_ytest.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N`: Number of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`D`: Number of training sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = df_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three preprocessing technique could be considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Z-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stdev(column):\n",
    "    avg = np.mean(column)\n",
    "    sd  = np.sum(np.square(column-avg))/(len(column)-1)\n",
    "    return np.sqrt(sd)\n",
    "\n",
    "def z_norm(column):\n",
    "    column = column - np.mean(column)\n",
    "    column = column/stdev(column)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Log-Transformation \n",
    "Transform each feature using $\\log(x_{i,j}+0.1)$ (assume natural log)\n",
    "\n",
    "The log transformation can be used to make highly skewed distributions less skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_X = np.log(df_X+0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Binarize(column):\n",
    "    \"\"\"For the input column, set values larger than the column mean to be 1, \n",
    "    rest set to be 0.\"\"\"\n",
    "    ones = column > column.mean()\n",
    "    zeros = column <= column.mean()\n",
    "    columnNew = pd.Series(np.zeros(len(column)))\n",
    "    columnNew[ones] = 1\n",
    "    return columnNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Preprocess the training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use binarization in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = df_X.apply(Binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest = df_Xtest.apply(Binarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modify `df_X` and `df_w` for Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add bia term to X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias = pd.DataFrame(bias,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_X = pd.concat([df_bias,df_X],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-arrange the column name\n",
    "modified_column_name = np.arange(D+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* df_Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_test = np.ones(len(df_Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bias_test = pd.DataFrame(bias_test,columns=['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the bias and df_X coloumn-wise. \n",
    "df_Xtest = pd.concat([df_bias_test,df_Xtest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Xtest.columns = modified_column_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Initialize the modified weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and initialize the the weight vector to 0. \n",
    "\n",
    "\\# weight = # features + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = np.zeros([D+1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w = pd.DataFrame(df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Put everything together\n",
    "Train the classifier, for each regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}\n",
    "\n",
    "Then, find the error rates (i.e., percentage of emails classified wrongly) for each $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  \"\"\"The sigmoid function\"\"\"\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def getErrorRate(prediction,y):\n",
    "    \"\"\"Calculate the percentage of emails classified wrongly\"\"\"\n",
    "    compare = prediction == y\n",
    "    errorRate = 1-compare.sum().values[0]/compare.shape[0]\n",
    "    return errorRate\n",
    "\n",
    "def findBestThreshold(pred,y):\n",
    "    \"\"\"Calculate error rate for threshold from 50 to 100,\n",
    "    find the threshold that produces the minimum error rate.\"\"\"\n",
    "    # create an array to store the error rate produced by each threshold.\n",
    "    store = np.zeros(50)\n",
    "    counter = 0\n",
    "    for i in np.arange(50,100):\n",
    "        ones = pred > (i/100)\n",
    "        pred_binary = pd.DataFrame(ones)\n",
    "        store[counter] = getErrorRate(pred_binary,y)\n",
    "        counter = counter +1\n",
    "    # find the index of the minimum error rate.     \n",
    "    resultIndex = np.argmin(store)\n",
    "    bestThreshold = np.arange(50,100)[resultIndex]\n",
    "    bestErrorRate = store[resultIndex]\n",
    "    return bestThreshold,bestErrorRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I'$- `identity_modified`: set the first entry of the identity matrix $I$ to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_modified = np.ones(D+1)\n",
    "identity_modified[0] = 0 \n",
    "identity_modified = np.diag(identity_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization parameter value $\\lambda$ = {1,2,...,9,10,15,20,...,95,100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = np.append(np.arange(1,10),np.arange(10,105,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`K` : number of regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_w_all`: a dataframe used to store all the weight vector from each regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w_all = pd.DataFrame(np.zeros((D+1,K)),columns=[params])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_error_rate`: a dataframed used to store the error rate for each regularization parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_error_rate = pd.DataFrame(np.zeros((K,2)),index = params,columns=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For regulation parameter 1\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 8\n",
      "\n",
      "For regulation parameter 2\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 4\n",
      "\n",
      "For regulation parameter 3\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 4\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 5\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 6\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 7\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 8\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 9\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 10\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 15\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 20\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 25\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 30\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 35\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 40\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 45\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 50\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 55\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 60\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 65\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 70\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 75\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 80\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 3\n",
      "\n",
      "For regulation parameter 85\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 90\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 95\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "For regulation parameter 100\n",
      "Weight vector converged, training is over.\n",
      "Number of loop 2\n",
      "\n",
      "The weight vector obtained through the newton's method.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.92580</td>\n",
       "      <td>-0.36678</td>\n",
       "      <td>-0.21629</td>\n",
       "      <td>-0.44506</td>\n",
       "      <td>0.54954</td>\n",
       "      <td>1.09004</td>\n",
       "      <td>0.66329</td>\n",
       "      <td>2.62833</td>\n",
       "      <td>0.92609</td>\n",
       "      <td>0.11068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48258</td>\n",
       "      <td>0.27090</td>\n",
       "      <td>-0.05700</td>\n",
       "      <td>-0.24255</td>\n",
       "      <td>1.60261</td>\n",
       "      <td>2.02712</td>\n",
       "      <td>-0.61364</td>\n",
       "      <td>0.71648</td>\n",
       "      <td>0.49469</td>\n",
       "      <td>0.39521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.88934</td>\n",
       "      <td>-0.31297</td>\n",
       "      <td>-0.19908</td>\n",
       "      <td>-0.36338</td>\n",
       "      <td>0.44957</td>\n",
       "      <td>1.01690</td>\n",
       "      <td>0.60968</td>\n",
       "      <td>2.38535</td>\n",
       "      <td>0.87070</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42419</td>\n",
       "      <td>0.25356</td>\n",
       "      <td>-0.05252</td>\n",
       "      <td>-0.22946</td>\n",
       "      <td>1.51290</td>\n",
       "      <td>1.89431</td>\n",
       "      <td>-0.45937</td>\n",
       "      <td>0.65515</td>\n",
       "      <td>0.45018</td>\n",
       "      <td>0.36046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.86601</td>\n",
       "      <td>-0.27641</td>\n",
       "      <td>-0.17952</td>\n",
       "      <td>-0.30896</td>\n",
       "      <td>0.38680</td>\n",
       "      <td>0.96785</td>\n",
       "      <td>0.57277</td>\n",
       "      <td>2.21369</td>\n",
       "      <td>0.83121</td>\n",
       "      <td>0.14690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.38507</td>\n",
       "      <td>0.23891</td>\n",
       "      <td>-0.05231</td>\n",
       "      <td>-0.21641</td>\n",
       "      <td>1.45090</td>\n",
       "      <td>1.80096</td>\n",
       "      <td>-0.36179</td>\n",
       "      <td>0.61536</td>\n",
       "      <td>0.42449</td>\n",
       "      <td>0.33742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.84895</td>\n",
       "      <td>-0.24886</td>\n",
       "      <td>-0.16100</td>\n",
       "      <td>-0.26830</td>\n",
       "      <td>0.34286</td>\n",
       "      <td>0.93073</td>\n",
       "      <td>0.54458</td>\n",
       "      <td>2.08152</td>\n",
       "      <td>0.80031</td>\n",
       "      <td>0.15715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.35637</td>\n",
       "      <td>0.22590</td>\n",
       "      <td>-0.05378</td>\n",
       "      <td>-0.20492</td>\n",
       "      <td>1.40331</td>\n",
       "      <td>1.72830</td>\n",
       "      <td>-0.29306</td>\n",
       "      <td>0.58574</td>\n",
       "      <td>0.40757</td>\n",
       "      <td>0.32081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.83547</td>\n",
       "      <td>-0.22685</td>\n",
       "      <td>-0.14414</td>\n",
       "      <td>-0.23598</td>\n",
       "      <td>0.31001</td>\n",
       "      <td>0.90079</td>\n",
       "      <td>0.52181</td>\n",
       "      <td>1.97453</td>\n",
       "      <td>0.77479</td>\n",
       "      <td>0.16456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.33409</td>\n",
       "      <td>0.21405</td>\n",
       "      <td>-0.05594</td>\n",
       "      <td>-0.19502</td>\n",
       "      <td>1.36451</td>\n",
       "      <td>1.66849</td>\n",
       "      <td>-0.24154</td>\n",
       "      <td>0.56213</td>\n",
       "      <td>0.39552</td>\n",
       "      <td>0.30825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.82425</td>\n",
       "      <td>-0.20859</td>\n",
       "      <td>-0.12895</td>\n",
       "      <td>-0.20928</td>\n",
       "      <td>0.28431</td>\n",
       "      <td>0.87564</td>\n",
       "      <td>0.50276</td>\n",
       "      <td>1.88501</td>\n",
       "      <td>0.75294</td>\n",
       "      <td>0.17001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.31612</td>\n",
       "      <td>0.20313</td>\n",
       "      <td>-0.05834</td>\n",
       "      <td>-0.18649</td>\n",
       "      <td>1.33163</td>\n",
       "      <td>1.61748</td>\n",
       "      <td>-0.20126</td>\n",
       "      <td>0.54252</td>\n",
       "      <td>0.38648</td>\n",
       "      <td>0.29839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.81456</td>\n",
       "      <td>-0.19303</td>\n",
       "      <td>-0.11527</td>\n",
       "      <td>-0.18661</td>\n",
       "      <td>0.26354</td>\n",
       "      <td>0.85394</td>\n",
       "      <td>0.48641</td>\n",
       "      <td>1.80831</td>\n",
       "      <td>0.73376</td>\n",
       "      <td>0.17409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30120</td>\n",
       "      <td>0.19300</td>\n",
       "      <td>-0.06077</td>\n",
       "      <td>-0.17908</td>\n",
       "      <td>1.30299</td>\n",
       "      <td>1.57291</td>\n",
       "      <td>-0.16880</td>\n",
       "      <td>0.52576</td>\n",
       "      <td>0.37941</td>\n",
       "      <td>0.29044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.80596</td>\n",
       "      <td>-0.17949</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.16699</td>\n",
       "      <td>0.24633</td>\n",
       "      <td>0.83485</td>\n",
       "      <td>0.47214</td>\n",
       "      <td>1.74143</td>\n",
       "      <td>0.71662</td>\n",
       "      <td>0.17717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28853</td>\n",
       "      <td>0.18357</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17261</td>\n",
       "      <td>1.27754</td>\n",
       "      <td>1.53328</td>\n",
       "      <td>-0.14204</td>\n",
       "      <td>0.51115</td>\n",
       "      <td>0.37370</td>\n",
       "      <td>0.28388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.79818</td>\n",
       "      <td>-0.16755</td>\n",
       "      <td>-0.09173</td>\n",
       "      <td>-0.14973</td>\n",
       "      <td>0.23179</td>\n",
       "      <td>0.81779</td>\n",
       "      <td>0.45951</td>\n",
       "      <td>1.68229</td>\n",
       "      <td>0.70109</td>\n",
       "      <td>0.17952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27760</td>\n",
       "      <td>0.17476</td>\n",
       "      <td>-0.06540</td>\n",
       "      <td>-0.16691</td>\n",
       "      <td>1.25459</td>\n",
       "      <td>1.49755</td>\n",
       "      <td>-0.11956</td>\n",
       "      <td>0.49821</td>\n",
       "      <td>0.36898</td>\n",
       "      <td>0.27836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.79102</td>\n",
       "      <td>-0.15688</td>\n",
       "      <td>-0.08155</td>\n",
       "      <td>-0.13438</td>\n",
       "      <td>0.21931</td>\n",
       "      <td>0.80237</td>\n",
       "      <td>0.44820</td>\n",
       "      <td>1.62940</td>\n",
       "      <td>0.68686</td>\n",
       "      <td>0.18131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26802</td>\n",
       "      <td>0.16651</td>\n",
       "      <td>-0.06753</td>\n",
       "      <td>-0.16185</td>\n",
       "      <td>1.23364</td>\n",
       "      <td>1.46501</td>\n",
       "      <td>-0.10041</td>\n",
       "      <td>0.48660</td>\n",
       "      <td>0.36499</td>\n",
       "      <td>0.27364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.76116</td>\n",
       "      <td>-0.11633</td>\n",
       "      <td>-0.04191</td>\n",
       "      <td>-0.07658</td>\n",
       "      <td>0.17602</td>\n",
       "      <td>0.74181</td>\n",
       "      <td>0.40514</td>\n",
       "      <td>1.42801</td>\n",
       "      <td>0.62920</td>\n",
       "      <td>0.18547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23309</td>\n",
       "      <td>0.13221</td>\n",
       "      <td>-0.07625</td>\n",
       "      <td>-0.14323</td>\n",
       "      <td>1.14913</td>\n",
       "      <td>1.33520</td>\n",
       "      <td>-0.03556</td>\n",
       "      <td>0.44198</td>\n",
       "      <td>0.35123</td>\n",
       "      <td>0.25727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.73683</td>\n",
       "      <td>-0.08851</td>\n",
       "      <td>-0.01458</td>\n",
       "      <td>-0.03747</td>\n",
       "      <td>0.14979</td>\n",
       "      <td>0.69790</td>\n",
       "      <td>0.37555</td>\n",
       "      <td>1.28940</td>\n",
       "      <td>0.58571</td>\n",
       "      <td>0.18588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21023</td>\n",
       "      <td>0.10644</td>\n",
       "      <td>-0.08235</td>\n",
       "      <td>-0.13123</td>\n",
       "      <td>1.08519</td>\n",
       "      <td>1.23951</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.41066</td>\n",
       "      <td>0.34238</td>\n",
       "      <td>0.24709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.71554</td>\n",
       "      <td>-0.06780</td>\n",
       "      <td>0.00542</td>\n",
       "      <td>-0.00866</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.66346</td>\n",
       "      <td>0.35345</td>\n",
       "      <td>1.18563</td>\n",
       "      <td>0.55081</td>\n",
       "      <td>0.18486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19355</td>\n",
       "      <td>0.08647</td>\n",
       "      <td>-0.08669</td>\n",
       "      <td>-0.12273</td>\n",
       "      <td>1.03325</td>\n",
       "      <td>1.16396</td>\n",
       "      <td>0.02551</td>\n",
       "      <td>0.38676</td>\n",
       "      <td>0.33556</td>\n",
       "      <td>0.23972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.69626</td>\n",
       "      <td>-0.05161</td>\n",
       "      <td>0.02067</td>\n",
       "      <td>0.01366</td>\n",
       "      <td>0.11863</td>\n",
       "      <td>0.63515</td>\n",
       "      <td>0.33604</td>\n",
       "      <td>1.10377</td>\n",
       "      <td>0.52179</td>\n",
       "      <td>0.18325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18057</td>\n",
       "      <td>0.07059</td>\n",
       "      <td>-0.08982</td>\n",
       "      <td>-0.11633</td>\n",
       "      <td>0.98936</td>\n",
       "      <td>1.10181</td>\n",
       "      <td>0.04189</td>\n",
       "      <td>0.36756</td>\n",
       "      <td>0.32977</td>\n",
       "      <td>0.23388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1.67846</td>\n",
       "      <td>-0.03852</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.03156</td>\n",
       "      <td>0.10839</td>\n",
       "      <td>0.61113</td>\n",
       "      <td>0.32181</td>\n",
       "      <td>1.03685</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.18138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17002</td>\n",
       "      <td>0.05768</td>\n",
       "      <td>-0.09210</td>\n",
       "      <td>-0.11126</td>\n",
       "      <td>0.95131</td>\n",
       "      <td>1.04925</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.35160</td>\n",
       "      <td>0.32461</td>\n",
       "      <td>0.22899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.66183</td>\n",
       "      <td>-0.02769</td>\n",
       "      <td>0.04226</td>\n",
       "      <td>0.04627</td>\n",
       "      <td>0.10018</td>\n",
       "      <td>0.59029</td>\n",
       "      <td>0.30984</td>\n",
       "      <td>0.98072</td>\n",
       "      <td>0.47561</td>\n",
       "      <td>0.17940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16119</td>\n",
       "      <td>0.04702</td>\n",
       "      <td>-0.09377</td>\n",
       "      <td>-0.10711</td>\n",
       "      <td>0.91773</td>\n",
       "      <td>1.00388</td>\n",
       "      <td>0.06234</td>\n",
       "      <td>0.33799</td>\n",
       "      <td>0.31988</td>\n",
       "      <td>0.22473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.64618</td>\n",
       "      <td>-0.01855</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.05857</td>\n",
       "      <td>0.09340</td>\n",
       "      <td>0.57191</td>\n",
       "      <td>0.29958</td>\n",
       "      <td>0.93267</td>\n",
       "      <td>0.45674</td>\n",
       "      <td>0.17740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15362</td>\n",
       "      <td>0.03808</td>\n",
       "      <td>-0.09498</td>\n",
       "      <td>-0.10361</td>\n",
       "      <td>0.88769</td>\n",
       "      <td>0.96411</td>\n",
       "      <td>0.06893</td>\n",
       "      <td>0.32616</td>\n",
       "      <td>0.31546</td>\n",
       "      <td>0.22094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-1.63135</td>\n",
       "      <td>-0.01074</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.06901</td>\n",
       "      <td>0.08769</td>\n",
       "      <td>0.55548</td>\n",
       "      <td>0.29062</td>\n",
       "      <td>0.89090</td>\n",
       "      <td>0.43997</td>\n",
       "      <td>0.17541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14703</td>\n",
       "      <td>0.03049</td>\n",
       "      <td>-0.09585</td>\n",
       "      <td>-0.10059</td>\n",
       "      <td>0.86055</td>\n",
       "      <td>0.92883</td>\n",
       "      <td>0.07399</td>\n",
       "      <td>0.31573</td>\n",
       "      <td>0.31129</td>\n",
       "      <td>0.21750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-1.61723</td>\n",
       "      <td>-0.00397</td>\n",
       "      <td>0.06212</td>\n",
       "      <td>0.07797</td>\n",
       "      <td>0.08279</td>\n",
       "      <td>0.54063</td>\n",
       "      <td>0.28269</td>\n",
       "      <td>0.85411</td>\n",
       "      <td>0.42492</td>\n",
       "      <td>0.17346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14121</td>\n",
       "      <td>0.02398</td>\n",
       "      <td>-0.09645</td>\n",
       "      <td>-0.09795</td>\n",
       "      <td>0.83583</td>\n",
       "      <td>0.89720</td>\n",
       "      <td>0.07794</td>\n",
       "      <td>0.30642</td>\n",
       "      <td>0.30734</td>\n",
       "      <td>0.21434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-1.60375</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.06674</td>\n",
       "      <td>0.08573</td>\n",
       "      <td>0.07853</td>\n",
       "      <td>0.52709</td>\n",
       "      <td>0.27561</td>\n",
       "      <td>0.82138</td>\n",
       "      <td>0.41130</td>\n",
       "      <td>0.17156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13601</td>\n",
       "      <td>0.01836</td>\n",
       "      <td>-0.09683</td>\n",
       "      <td>-0.09559</td>\n",
       "      <td>0.81314</td>\n",
       "      <td>0.86862</td>\n",
       "      <td>0.08104</td>\n",
       "      <td>0.29802</td>\n",
       "      <td>0.30357</td>\n",
       "      <td>0.21140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-1.59084</td>\n",
       "      <td>0.00717</td>\n",
       "      <td>0.07068</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.07479</td>\n",
       "      <td>0.51467</td>\n",
       "      <td>0.26921</td>\n",
       "      <td>0.79198</td>\n",
       "      <td>0.39891</td>\n",
       "      <td>0.16971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13132</td>\n",
       "      <td>0.01346</td>\n",
       "      <td>-0.09706</td>\n",
       "      <td>-0.09347</td>\n",
       "      <td>0.79221</td>\n",
       "      <td>0.84260</td>\n",
       "      <td>0.08348</td>\n",
       "      <td>0.29038</td>\n",
       "      <td>0.29996</td>\n",
       "      <td>0.20866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-1.57843</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.07407</td>\n",
       "      <td>0.09846</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.50319</td>\n",
       "      <td>0.26338</td>\n",
       "      <td>0.76539</td>\n",
       "      <td>0.38756</td>\n",
       "      <td>0.16792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12706</td>\n",
       "      <td>0.00916</td>\n",
       "      <td>-0.09715</td>\n",
       "      <td>-0.09155</td>\n",
       "      <td>0.77281</td>\n",
       "      <td>0.81877</td>\n",
       "      <td>0.08540</td>\n",
       "      <td>0.28338</td>\n",
       "      <td>0.29650</td>\n",
       "      <td>0.20608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-1.56649</td>\n",
       "      <td>0.01593</td>\n",
       "      <td>0.07699</td>\n",
       "      <td>0.10371</td>\n",
       "      <td>0.06847</td>\n",
       "      <td>0.49253</td>\n",
       "      <td>0.25804</td>\n",
       "      <td>0.74116</td>\n",
       "      <td>0.37711</td>\n",
       "      <td>0.16618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12317</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.09713</td>\n",
       "      <td>-0.08978</td>\n",
       "      <td>0.75474</td>\n",
       "      <td>0.79683</td>\n",
       "      <td>0.08692</td>\n",
       "      <td>0.27693</td>\n",
       "      <td>0.29317</td>\n",
       "      <td>0.20364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.55498</td>\n",
       "      <td>0.01964</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>0.10837</td>\n",
       "      <td>0.06578</td>\n",
       "      <td>0.48259</td>\n",
       "      <td>0.25312</td>\n",
       "      <td>0.71897</td>\n",
       "      <td>0.36745</td>\n",
       "      <td>0.16449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11959</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>-0.09703</td>\n",
       "      <td>-0.08815</td>\n",
       "      <td>0.73784</td>\n",
       "      <td>0.77654</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.27096</td>\n",
       "      <td>0.28996</td>\n",
       "      <td>0.20133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-1.54385</td>\n",
       "      <td>0.02299</td>\n",
       "      <td>0.08171</td>\n",
       "      <td>0.11253</td>\n",
       "      <td>0.06334</td>\n",
       "      <td>0.47328</td>\n",
       "      <td>0.24855</td>\n",
       "      <td>0.69854</td>\n",
       "      <td>0.35849</td>\n",
       "      <td>0.16286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11628</td>\n",
       "      <td>-0.00099</td>\n",
       "      <td>-0.09685</td>\n",
       "      <td>-0.08663</td>\n",
       "      <td>0.72200</td>\n",
       "      <td>0.75768</td>\n",
       "      <td>0.08904</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.28687</td>\n",
       "      <td>0.19912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-1.53309</td>\n",
       "      <td>0.02602</td>\n",
       "      <td>0.08362</td>\n",
       "      <td>0.11623</td>\n",
       "      <td>0.06110</td>\n",
       "      <td>0.46452</td>\n",
       "      <td>0.24430</td>\n",
       "      <td>0.67965</td>\n",
       "      <td>0.35013</td>\n",
       "      <td>0.16128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11320</td>\n",
       "      <td>-0.00367</td>\n",
       "      <td>-0.09662</td>\n",
       "      <td>-0.08521</td>\n",
       "      <td>0.70710</td>\n",
       "      <td>0.74010</td>\n",
       "      <td>0.08975</td>\n",
       "      <td>0.26020</td>\n",
       "      <td>0.28388</td>\n",
       "      <td>0.19702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.52267</td>\n",
       "      <td>0.02877</td>\n",
       "      <td>0.08529</td>\n",
       "      <td>0.11956</td>\n",
       "      <td>0.05905</td>\n",
       "      <td>0.45626</td>\n",
       "      <td>0.24033</td>\n",
       "      <td>0.66210</td>\n",
       "      <td>0.34233</td>\n",
       "      <td>0.15974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11034</td>\n",
       "      <td>-0.00607</td>\n",
       "      <td>-0.09634</td>\n",
       "      <td>-0.08388</td>\n",
       "      <td>0.69304</td>\n",
       "      <td>0.72365</td>\n",
       "      <td>0.09027</td>\n",
       "      <td>0.25533</td>\n",
       "      <td>0.28099</td>\n",
       "      <td>0.19501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.51256</td>\n",
       "      <td>0.03128</td>\n",
       "      <td>0.08675</td>\n",
       "      <td>0.12254</td>\n",
       "      <td>0.05716</td>\n",
       "      <td>0.44845</td>\n",
       "      <td>0.23660</td>\n",
       "      <td>0.64575</td>\n",
       "      <td>0.33501</td>\n",
       "      <td>0.15826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.10766</td>\n",
       "      <td>-0.00824</td>\n",
       "      <td>-0.09602</td>\n",
       "      <td>-0.08262</td>\n",
       "      <td>0.67974</td>\n",
       "      <td>0.70821</td>\n",
       "      <td>0.09065</td>\n",
       "      <td>0.25074</td>\n",
       "      <td>0.27819</td>\n",
       "      <td>0.19307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2        3       4       5       6       7   \\\n",
       "1   -1.92580 -0.36678 -0.21629 -0.44506 0.54954 1.09004 0.66329 2.62833   \n",
       "2   -1.88934 -0.31297 -0.19908 -0.36338 0.44957 1.01690 0.60968 2.38535   \n",
       "3   -1.86601 -0.27641 -0.17952 -0.30896 0.38680 0.96785 0.57277 2.21369   \n",
       "4   -1.84895 -0.24886 -0.16100 -0.26830 0.34286 0.93073 0.54458 2.08152   \n",
       "5   -1.83547 -0.22685 -0.14414 -0.23598 0.31001 0.90079 0.52181 1.97453   \n",
       "6   -1.82425 -0.20859 -0.12895 -0.20928 0.28431 0.87564 0.50276 1.88501   \n",
       "7   -1.81456 -0.19303 -0.11527 -0.18661 0.26354 0.85394 0.48641 1.80831   \n",
       "8   -1.80596 -0.17949 -0.10292 -0.16699 0.24633 0.83485 0.47214 1.74143   \n",
       "9   -1.79818 -0.16755 -0.09173 -0.14973 0.23179 0.81779 0.45951 1.68229   \n",
       "10  -1.79102 -0.15688 -0.08155 -0.13438 0.21931 0.80237 0.44820 1.62940   \n",
       "15  -1.76116 -0.11633 -0.04191 -0.07658 0.17602 0.74181 0.40514 1.42801   \n",
       "20  -1.73683 -0.08851 -0.01458 -0.03747 0.14979 0.69790 0.37555 1.28940   \n",
       "25  -1.71554 -0.06780  0.00542 -0.00866 0.13184 0.66346 0.35345 1.18563   \n",
       "30  -1.69626 -0.05161  0.02067  0.01366 0.11863 0.63515 0.33604 1.10377   \n",
       "35  -1.67846 -0.03852  0.03264  0.03156 0.10839 0.61113 0.32181 1.03685   \n",
       "40  -1.66183 -0.02769  0.04226  0.04627 0.10018 0.59029 0.30984 0.98072   \n",
       "45  -1.64618 -0.01855  0.05013  0.05857 0.09340 0.57191 0.29958 0.93267   \n",
       "50  -1.63135 -0.01074  0.05665  0.06901 0.08769 0.55548 0.29062 0.89090   \n",
       "55  -1.61723 -0.00397  0.06212  0.07797 0.08279 0.54063 0.28269 0.85411   \n",
       "60  -1.60375  0.00195  0.06674  0.08573 0.07853 0.52709 0.27561 0.82138   \n",
       "65  -1.59084  0.00717  0.07068  0.09251 0.07479 0.51467 0.26921 0.79198   \n",
       "70  -1.57843  0.01180  0.07407  0.09846 0.07146 0.50319 0.26338 0.76539   \n",
       "75  -1.56649  0.01593  0.07699  0.10371 0.06847 0.49253 0.25804 0.74116   \n",
       "80  -1.55498  0.01964  0.07951  0.10837 0.06578 0.48259 0.25312 0.71897   \n",
       "85  -1.54385  0.02299  0.08171  0.11253 0.06334 0.47328 0.24855 0.69854   \n",
       "90  -1.53309  0.02602  0.08362  0.11623 0.06110 0.46452 0.24430 0.67965   \n",
       "95  -1.52267  0.02877  0.08529  0.11956 0.05905 0.45626 0.24033 0.66210   \n",
       "100 -1.51256  0.03128  0.08675  0.12254 0.05716 0.44845 0.23660 0.64575   \n",
       "\n",
       "         8       9    ...         48       49       50       51      52  \\\n",
       "1   0.92609 0.11068   ...   -0.48258  0.27090 -0.05700 -0.24255 1.60261   \n",
       "2   0.87070 0.13230   ...   -0.42419  0.25356 -0.05252 -0.22946 1.51290   \n",
       "3   0.83121 0.14690   ...   -0.38507  0.23891 -0.05231 -0.21641 1.45090   \n",
       "4   0.80031 0.15715   ...   -0.35637  0.22590 -0.05378 -0.20492 1.40331   \n",
       "5   0.77479 0.16456   ...   -0.33409  0.21405 -0.05594 -0.19502 1.36451   \n",
       "6   0.75294 0.17001   ...   -0.31612  0.20313 -0.05834 -0.18649 1.33163   \n",
       "7   0.73376 0.17409   ...   -0.30120  0.19300 -0.06077 -0.17908 1.30299   \n",
       "8   0.71662 0.17717   ...   -0.28853  0.18357 -0.06314 -0.17261 1.27754   \n",
       "9   0.70109 0.17952   ...   -0.27760  0.17476 -0.06540 -0.16691 1.25459   \n",
       "10  0.68686 0.18131   ...   -0.26802  0.16651 -0.06753 -0.16185 1.23364   \n",
       "15  0.62920 0.18547   ...   -0.23309  0.13221 -0.07625 -0.14323 1.14913   \n",
       "20  0.58571 0.18588   ...   -0.21023  0.10644 -0.08235 -0.13123 1.08519   \n",
       "25  0.55081 0.18486   ...   -0.19355  0.08647 -0.08669 -0.12273 1.03325   \n",
       "30  0.52179 0.18325   ...   -0.18057  0.07059 -0.08982 -0.11633 0.98936   \n",
       "35  0.49706 0.18138   ...   -0.17002  0.05768 -0.09210 -0.11126 0.95131   \n",
       "40  0.47561 0.17940   ...   -0.16119  0.04702 -0.09377 -0.10711 0.91773   \n",
       "45  0.45674 0.17740   ...   -0.15362  0.03808 -0.09498 -0.10361 0.88769   \n",
       "50  0.43997 0.17541   ...   -0.14703  0.03049 -0.09585 -0.10059 0.86055   \n",
       "55  0.42492 0.17346   ...   -0.14121  0.02398 -0.09645 -0.09795 0.83583   \n",
       "60  0.41130 0.17156   ...   -0.13601  0.01836 -0.09683 -0.09559 0.81314   \n",
       "65  0.39891 0.16971   ...   -0.13132  0.01346 -0.09706 -0.09347 0.79221   \n",
       "70  0.38756 0.16792   ...   -0.12706  0.00916 -0.09715 -0.09155 0.77281   \n",
       "75  0.37711 0.16618   ...   -0.12317  0.00537 -0.09713 -0.08978 0.75474   \n",
       "80  0.36745 0.16449   ...   -0.11959  0.00201 -0.09703 -0.08815 0.73784   \n",
       "85  0.35849 0.16286   ...   -0.11628 -0.00099 -0.09685 -0.08663 0.72200   \n",
       "90  0.35013 0.16128   ...   -0.11320 -0.00367 -0.09662 -0.08521 0.70710   \n",
       "95  0.34233 0.15974   ...   -0.11034 -0.00607 -0.09634 -0.08388 0.69304   \n",
       "100 0.33501 0.15826   ...   -0.10766 -0.00824 -0.09602 -0.08262 0.67974   \n",
       "\n",
       "         53       54      55      56      57  \n",
       "1   2.02712 -0.61364 0.71648 0.49469 0.39521  \n",
       "2   1.89431 -0.45937 0.65515 0.45018 0.36046  \n",
       "3   1.80096 -0.36179 0.61536 0.42449 0.33742  \n",
       "4   1.72830 -0.29306 0.58574 0.40757 0.32081  \n",
       "5   1.66849 -0.24154 0.56213 0.39552 0.30825  \n",
       "6   1.61748 -0.20126 0.54252 0.38648 0.29839  \n",
       "7   1.57291 -0.16880 0.52576 0.37941 0.29044  \n",
       "8   1.53328 -0.14204 0.51115 0.37370 0.28388  \n",
       "9   1.49755 -0.11956 0.49821 0.36898 0.27836  \n",
       "10  1.46501 -0.10041 0.48660 0.36499 0.27364  \n",
       "15  1.33520 -0.03556 0.44198 0.35123 0.25727  \n",
       "20  1.23951  0.00164 0.41066 0.34238 0.24709  \n",
       "25  1.16396  0.02551 0.38676 0.33556 0.23972  \n",
       "30  1.10181  0.04189 0.36756 0.32977 0.23388  \n",
       "35  1.04925  0.05364 0.35160 0.32461 0.22899  \n",
       "40  1.00388  0.06234 0.33799 0.31988 0.22473  \n",
       "45  0.96411  0.06893 0.32616 0.31546 0.22094  \n",
       "50  0.92883  0.07399 0.31573 0.31129 0.21750  \n",
       "55  0.89720  0.07794 0.30642 0.30734 0.21434  \n",
       "60  0.86862  0.08104 0.29802 0.30357 0.21140  \n",
       "65  0.84260  0.08348 0.29038 0.29996 0.20866  \n",
       "70  0.81877  0.08540 0.28338 0.29650 0.20608  \n",
       "75  0.79683  0.08692 0.27693 0.29317 0.20364  \n",
       "80  0.77654  0.08811 0.27096 0.28996 0.20133  \n",
       "85  0.75768  0.08904 0.26540 0.28687 0.19912  \n",
       "90  0.74010  0.08975 0.26020 0.28388 0.19702  \n",
       "95  0.72365  0.09027 0.25533 0.28099 0.19501  \n",
       "100 0.70821  0.09065 0.25074 0.27819 0.19307  \n",
       "\n",
       "[28 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for L in params:\n",
    "    counter  = 0\n",
    "    for i in np.arange(500):\n",
    "        #_________________________________________________________#\n",
    "        ### 1. Calcualte mu \n",
    "        df_mu = df_X.dot(df_w)\n",
    "        df_mu = df_mu.apply(sigmoid)\n",
    "        \n",
    "        #_________________________________________________________#\n",
    "        ### 2. Calculate first derivative of NLL: g \n",
    "        df_w_modified = df_w.copy()\n",
    "        df_w_modified.iloc[0] = 0\n",
    "        df_g = df_X.transpose().dot(df_mu-df_y)+L*df_w_modified\n",
    "\n",
    "        #_________________________________________________________#\n",
    "        ### 3. Calculate second derivative of NLL: H     \n",
    "        df_S = df_mu*(1-df_mu)\n",
    "        df_S = np.diag(df_S.transpose().values.tolist()[0])\n",
    "        df_S = pd.DataFrame(df_S)\n",
    "\n",
    "        df_H = df_X.transpose().dot(df_S)\n",
    "        df_H = df_H.dot(df_X)\n",
    "        df_H = df_H + L*identity_modified\n",
    "        \n",
    "        #_________________________________________________________#  \n",
    "        ### 4. Update weight vector  \n",
    "        df_H_inverse = pd.DataFrame(np.linalg.pinv(df_H.values))\n",
    "        df_w_update = df_w - df_H_inverse.dot(df_g)\n",
    "        \n",
    "        #_________________________________________________________# \n",
    "        ### 5. Check whether the weight vector has already converged.       \n",
    "        if df_w_update.round(6).equals(df_w.round(6)):\n",
    "            # Store the converged weight vector.\n",
    "            df_w_all[L] = df_w[0]\n",
    "            \n",
    "            #_____________________________________________________# \n",
    "            ### 6. Calculate the error rate for training dataset. \n",
    "            df_pred = df_X.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_y)\n",
    "            df_error_rate.loc[L,'train'] = errorRate\n",
    "            \n",
    "            ### 6. Calculate the error rate for test dataset.\n",
    "            df_pred = df_Xtest.dot(df_w)\n",
    "            df_pred = df_pred.apply(sigmoid)\n",
    "            threshold,errorRate = findBestThreshold(df_pred,df_ytest)\n",
    "            df_error_rate.loc[L,'test'] = errorRate\n",
    "            break\n",
    "        else:\n",
    "            df_w = df_w_update\n",
    "            counter = counter + 1\n",
    "\n",
    "    if counter == 500:\n",
    "        print('Weight vector didnt converged')\n",
    "    else:\n",
    "        print('\\nFor regulation parameter',L)\n",
    "        print('Weight vector converged, training is over.')\n",
    "        print('Number of loop',counter)\n",
    "\n",
    "df_w_all = df_w_all.transpose()\n",
    "print(\"\\nThe weight vector obtained through the newton's method.\")\n",
    "display(df_w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The error rate when lambda = 1,10 and 100 is\n",
      "       train    test\n",
      "1   0.06786 0.07031\n",
      "10  0.07341 0.06966\n",
      "100 0.09592 0.09115\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe error rate when lambda = 1,10 and 100 is\\n',df_error_rate.loc[[1,10,100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the Graph: Error Rates versus $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.00000</td>\n",
       "      <td>28.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.07845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.01028</td>\n",
       "      <td>0.00741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.06786</td>\n",
       "      <td>0.06966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.07227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.08124</td>\n",
       "      <td>0.07585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.09250</td>\n",
       "      <td>0.08496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.09592</td>\n",
       "      <td>0.09115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train     test\n",
       "count 28.00000 28.00000\n",
       "mean   0.08178  0.07845\n",
       "std    0.01028  0.00741\n",
       "min    0.06786  0.06966\n",
       "25%    0.07162  0.07227\n",
       "50%    0.08124  0.07585\n",
       "75%    0.09250  0.08496\n",
       "max    0.09592  0.09115"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error_rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the error rates to a csv file.\n",
    "df_error_rate.to_csv('Q3_ErrorRates_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCisiIiLi0v4/EQVH7nH4le8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099bbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the figure size\n",
    "fig=plt.figure(figsize=(9,6))\n",
    "\n",
    "# x axis: the regularization parameters lambda.\n",
    "x = df_error_rate.index.values\n",
    "# y axis: the error rates\n",
    "y1 = 100*df_error_rate.train.values\n",
    "y2 = 100*df_error_rate.test.values\n",
    "\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "\n",
    "plt.title('Error Rate for lambda = {1,2,...,9,10,15,20,...,95,100}',fontsize=15)\n",
    "plt.xlabel('lambda', fontsize=14)\n",
    "plt.ylabel('Error Rate %', fontsize=14)\n",
    "\n",
    "# legend\n",
    "plt.legend(('Training error', 'Test error'),fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
